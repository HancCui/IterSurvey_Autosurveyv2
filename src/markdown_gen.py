import subprocess
import tempfile
import os
import shutil
import re
import glob

def extract_arxiv_id(markdown_text):
    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… [arxiv_id] æ ¼å¼çš„å¼•ç”¨ï¼ŒåªåŒ¹é…åŒ…å«arXiv IDæ ¼å¼çš„ä¸­æ‹¬å·
    # åŒ¹é…æ ¼å¼: [YYMM.NNNNN] ç­‰ï¼Œæ”¯æŒç‰ˆæœ¬å·vNï¼Œé¿å…åŒ¹é…å…¶ä»–ä¸­æ‹¬å·æ–‡æœ¬
    cite_pattern = re.compile(r'\[([^\]]*\d{2,4}\.\d{2,5}(?:v\d+)?[^\]]*)\]')
    matches = cite_pattern.findall(markdown_text)

    seen_citations = set()  # ç”¨äºå»é‡

    for match in matches:
        # ä½¿ç”¨å¤šç§åˆ†éš”ç¬¦åˆ†å‰²å¼•ç”¨ï¼šåˆ†å·ã€é€—å·ã€ç©ºæ ¼
        parts = re.split(r'[;,\s]+', match)

        for part in parts:
            part = part.strip()
            part = part.split('v')[0]
            # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„arXiv ID
            if part and is_arxiv_id(part):
                if part not in seen_citations:
                    seen_citations.add(part)

    return list(seen_citations)



def is_arxiv_id(s: str) -> bool:
    """
    åˆ¤æ–­ä¸€ä¸ªå­—ç¬¦ä¸²æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ arXiv IDã€‚

    è¯¥å‡½æ•°ä¼šæ£€æŸ¥ä»¥ä¸‹æ ¼å¼ï¼š
    1. æ–°æ ¼å¼: YYMM.NNNN(N) (ä¾‹å¦‚ 1501.01234 æˆ– 0801.1234)
    2. æ—§æ ¼å¼: archive/YYMMNNN (ä¾‹å¦‚ hep-th/0101001)
    3. å¯é€‰çš„ç‰ˆæœ¬å· (ä¾‹å¦‚ v1, v2)
    4. å¯é€‰çš„ "arXiv:" å‰ç¼€

    Args:
        s: å¾…æ£€æŸ¥çš„å­—ç¬¦ä¸²ã€‚

    Returns:
        å¦‚æœå­—ç¬¦ä¸²æ˜¯æœ‰æ•ˆçš„ arXiv IDï¼Œè¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚
    """
    if not isinstance(s, str) or not s:
        return False

    # åŒ¹é…æ–°æ ¼å¼ï¼šYYMM.NNNN æˆ– YYMM.NNNNNï¼Œå¯é€‰ vN
    # \d{4}   -> YYMM (å¹´ä»½å’Œæœˆä»½)
    # \.      -> ç‚¹å·
    # \d{4,5} -> NNNN æˆ– NNNNN (4ä½æˆ–5ä½åºåˆ—å·)
    # (v\d+)? -> å¯é€‰çš„ç‰ˆæœ¬å·
    new_format_regex = r'^\d{4}\.\d{4,5}(v\d+)?$'

    # åŒ¹é…æ—§æ ¼å¼ï¼šarchive/YYMMNNNï¼Œå¯é€‰ vN
    # [a-z-]+      -> æ¡£æ¡ˆåï¼Œå¦‚ hep-th, cs
    # (\.[a-z]{2})? -> å¯é€‰çš„å­åˆ†ç±»ï¼Œå¦‚ .cl (å·²è½¬ä¸ºå°å†™)
    # \/           -> æ–œæ 
    # \d{7}        -> YYMMNNN (å¹´ä»½ã€æœˆä»½ã€åºåˆ—å·)
    # (v\d+)?      -> å¯é€‰çš„ç‰ˆæœ¬å·
    old_format_regex = r'^[a-z-]+(\.[a-z]{2})?/\d{7}(v\d+)?$'

    # å»æ‰å¯é€‰çš„ "arXiv:" å‰ç¼€ï¼Œå¹¶ç»Ÿä¸€è½¬ä¸ºå°å†™ä»¥åŒ¹é…æ—§æ ¼å¼
    test_str = s.lower()
    if test_str.startswith('arxiv:'):
        test_str = test_str[6:]

    # è¿›è¡Œæ­£åˆ™åŒ¹é…
    if re.match(new_format_regex, test_str) or re.match(old_format_regex, test_str):
        return True

    return False


def compile_latex_pbpp(project_path: str):
    """
    Manually compiles a LaTeX project using the pdflatex -> bibtex -> pdflatex -> pdflatex sequence.

    Args:
        project_path (str): The absolute or relative path to the directory containing
                            the .tex, .bib, and .sty files.
    """
    # --- 1. éªŒè¯è·¯å¾„å¹¶æŸ¥æ‰¾ä¸» .tex æ–‡ä»¶ ---
    if not os.path.isdir(project_path):
        print(f"âŒ é”™è¯¯ï¼šè·¯å¾„ '{project_path}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ–‡ä»¶å¤¹ã€‚")
        return

    # ä½¿ç”¨ glob æŸ¥æ‰¾ç›®å½•ä¸‹çš„ .tex æ–‡ä»¶
    tex_files = glob.glob(os.path.join(project_path, '*.tex'))

    if not tex_files:
        print(f"âŒ é”™è¯¯ï¼šåœ¨æ–‡ä»¶å¤¹ '{project_path}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .tex æ–‡ä»¶ã€‚")
        return

    # å¦‚æœæœ‰ main.texï¼Œä¼˜å…ˆä½¿ç”¨å®ƒï¼›å¦åˆ™ï¼Œå¦‚æœåªæœ‰ä¸€ä¸ª .tex æ–‡ä»¶ï¼Œå°±ç”¨é‚£ä¸ª
    main_tex_path = os.path.join(project_path, 'main.tex')
    if main_tex_path in tex_files:
        target_tex_file = main_tex_path
    elif len(tex_files) == 1:
        target_tex_file = tex_files[0]
    else:
        # å¦‚æœæœ‰å¤šä¸ª .tex æ–‡ä»¶ä¸”æ²¡æœ‰ main.texï¼Œåˆ™æ— æ³•ç¡®å®šä¸»æ–‡ä»¶
        print(f"âŒ é”™è¯¯ï¼šæ‰¾åˆ°å¤šä¸ª .tex æ–‡ä»¶ï¼Œæ— æ³•ç¡®å®šä¸»ç¼–è¯‘æ–‡ä»¶ã€‚è¯·ç¡®ä¿åªæœ‰ä¸€ä¸ª .tex æ–‡ä»¶ï¼Œæˆ–è€…å…¶ä¸­ä¸€ä¸ªåä¸º 'main.tex'ã€‚")
        print(f"   æ‰¾åˆ°çš„æ–‡ä»¶: {[os.path.basename(f) for f in tex_files]}")
        return

    # ä»å®Œæ•´è·¯å¾„ä¸­è·å–ä¸å¸¦æ‰©å±•åçš„åŸºæœ¬æ–‡ä»¶å (ä¾‹å¦‚ 'main')
    base_name = os.path.splitext(os.path.basename(target_tex_file))[0]
    print(f"â–¶ï¸  å¼€å§‹ç¼–è¯‘é¡¹ç›®: {project_path}")
    print(f"   ä¸»æ–‡ä»¶: {os.path.basename(target_tex_file)}")

    # --- 2. å®šä¹‰ç¼–è¯‘å‘½ä»¤åºåˆ— ---
    # æ·»åŠ  '-interaction=nonstopmode' å¯ä»¥é˜²æ­¢ LaTeX åœ¨é‡åˆ°å°é”™è¯¯æ—¶æš‚åœå¹¶ç­‰å¾…ç”¨æˆ·è¾“å…¥
    commands = [
        ['pdflatex', '-interaction=nonstopmode', base_name],
        ['bibtex', base_name],
        ['pdflatex', '-interaction=nonstopmode', base_name],
        ['pdflatex', '-interaction=nonstopmode', base_name]
    ]

    # --- 3. ä¾æ¬¡æ‰§è¡Œå‘½ä»¤ ---
    for i, command in enumerate(commands):
        step_name = command[0]
        print(f"\n--- æ­¥éª¤ {i + 1}/{len(commands)}: æ­£åœ¨è¿è¡Œ {step_name} ---")

        try:
            # ä½¿ç”¨ subprocess.run æ¥æ‰§è¡Œå‘½ä»¤
            # cwd=project_path ç¡®ä¿å‘½ä»¤åœ¨æ­£ç¡®çš„æ–‡ä»¶å¤¹ä¸‹æ‰§è¡Œ
            # check=True å¦‚æœå‘½ä»¤è¿”å›éé›¶é€€å‡ºç ï¼ˆå³å‡ºé”™ï¼‰ï¼Œåˆ™ä¼šæŠ›å‡ºå¼‚å¸¸
            # capture_output=True æ•è·æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯
            # text=True å°†æ•è·çš„è¾“å‡ºè§£ç ä¸ºæ–‡æœ¬
            result = subprocess.run(
                command,
                cwd=project_path,
                check=True,
                capture_output=True,
                text=True,
                encoding='utf-8'
            )
            print(f"âœ… '{' '.join(command)}' æ‰§è¡ŒæˆåŠŸã€‚")

        except FileNotFoundError:
            print(f"âŒ è‡´å‘½é”™è¯¯: å‘½ä»¤ '{command[0]}' æœªæ‰¾åˆ°ã€‚")
            print("   è¯·ç¡®ä¿æ‚¨çš„ TeX å‘è¡Œç‰ˆ (å¦‚ TeX Live, MiKTeX) çš„ bin ç›®å½•åœ¨ç³»ç»Ÿçš„ PATH ç¯å¢ƒå˜é‡ä¸­ã€‚")
            # return # ä¸­æ–­æ‰§è¡Œ
        except subprocess.CalledProcessError as e:
            # å¦‚æœ LaTeX ç¼–è¯‘å‡ºé”™ï¼Œæ‰“å°å…¶è¾“å‡ºæ—¥å¿—
            print(f"âŒ é”™è¯¯ï¼š'{' '.join(command)}' æ‰§è¡Œå¤±è´¥ã€‚")
            print(f"   LaTeX è¿”å›äº†é”™è¯¯ï¼Œè¯·æ£€æŸ¥ä¸‹é¢çš„æ—¥å¿—ï¼š")
            print("-" * 50)
            # LaTeX çš„é”™è¯¯ä¿¡æ¯ä¸»è¦åœ¨ stdout ä¸­
            print(e.stdout)
            print("-" * 50)
            log_file = os.path.join(project_path, base_name + '.log')
            print(f"   æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: {log_file}")
            # return # ä¸­æ–­æ‰§è¡Œ

    final_pdf = os.path.join(project_path, base_name + '.pdf')
    print("\n==========================================")
    if os.path.exists(final_pdf):
        print(f"ğŸ‰ ç¼–è¯‘æˆåŠŸå®Œæˆï¼")
        print(f"   è¾“å‡ºæ–‡ä»¶ä½äº: {final_pdf}")
    else:
        print(f"âš ï¸ è­¦å‘Šï¼šç¼–è¯‘è¿‡ç¨‹æœªæŠ¥å‘Šé”™è¯¯ï¼Œä½†æœªæ‰¾åˆ°æœ€ç»ˆçš„ PDF æ–‡ä»¶ã€‚")
    print("==========================================")





def generate_markdown_code_cite_title(survey, markdown_path, api_model, db):

    from src.prompt import TO_MD_PROMPT, FOREST_TO_MERMAID_PROMPT

    def extract_markdown_code(response):
        # æ‰¾åˆ° ```markdown çš„å¼€å§‹ä½ç½®
        start_marker = '```markdown\n'
        start_idx = response.find(start_marker)
        if start_idx == -1:
            return ""

        # ä»å¼€å§‹ä½ç½®ä¹‹åå¯»æ‰¾å†…å®¹
        content_start = start_idx + len(start_marker)

        # æ‰¾åˆ°æœ€åä¸€ä¸ª ```
        end_idx = response.rfind('```')
        if end_idx <= start_idx:
            return ""

        return response[content_start:end_idx]

    def extract_mermaid_code(response):
        pattern = r'```mermaid\n(.*?)\n```'
        match = re.search(pattern, response, re.DOTALL)
        if match:
            return match.group(1)
        return ""

    section_markdown_list = []
    section_markdown_list.append(f"# {survey.title}")
    section_markdown_list.append(f"\n{survey.abstract}")  # Abstractä½œä¸ºå†…å®¹è€Œä¸æ˜¯æ ‡é¢˜

    # å¹¶è¡Œç”Ÿæˆå„èŠ‚çš„ Markdown å†…å®¹ï¼Œä¿æŒè¾“å‡ºé¡ºåºä¸å˜
    from concurrent.futures import ThreadPoolExecutor, as_completed

    def _process_single_section(section_idx, section):
        print(f"Generating markdown code for section {section_idx}...")
        section_title_w_fig = f"## {section.title}\n\n"
        if section.figs:
            print(f"Section {section.title} has {len(section.figs)} figures.")
            for fig in section.figs.values():
                if 'begin{forest}' in fig:
                    mermaid_code = ""
                    for attempt in range(3):
                        response = api_model.chat(FOREST_TO_MERMAID_PROMPT.replace("{{FOREST_CONTENT}}", fig))
                        mermaid_code = extract_mermaid_code(response)
                        if len(mermaid_code) > 0:
                            break
                        else:
                            print(f"Warning: Failed to convert forest tree to mermaid code, attempt {attempt + 1} of 3")
                    section_title_w_fig += mermaid_code + '\n\n'
                else:
                    section_title_w_fig += fig + '\n\n'
        if section.tables:
            print(f"Section {section.title} has {len(section.tables)} tables.")
            for table in section.tables.values():
                section_title_w_fig += table + '\n\n'
        section_content = section.to_content_str()
        section_content = section_content.replace(f"## {section.title}\n", section_title_w_fig)

        prompt = TO_MD_PROMPT.replace("{{SECTION_CONTENT}}", section_content)
        response = api_model.chat(prompt)
        section_content_markdown = extract_markdown_code(response)
        return section_idx, section_content_markdown

    futures = []
    ordered_results = {i: None for i in range(len(survey.sections))}
    with ThreadPoolExecutor(max_workers=min(8, max(1, os.cpu_count() or 4))) as executor:
        for section_idx, section in enumerate(survey.sections):
            futures.append(executor.submit(_process_single_section, section_idx, section))
        for future in as_completed(futures):
            idx, content_md = future.result()
            ordered_results[idx] = content_md

    for i in range(len(survey.sections)):
        section_markdown_list.append(ordered_results[i])

    # åŸºäºâ€œè®ºæ–‡æ ‡é¢˜â€çš„å¼•ç”¨è§£æä¸ç»Ÿä¸€ç¼–å·ï¼ˆæ–¹æ‹¬å·å†…åˆ†å·ä¼˜å…ˆï¼Œå…¼å®¹é€—å·ï¼‰
    print("Extracting all title-based citations from survey content...")
    survey_content = '\n'.join(section_markdown_list)

    # åŒ¹é…ä»»æ„æ–¹æ‹¬å·å†…å®¹ï¼Œåç»­ç­›é€‰ä¸ºå¼•ç”¨
    bracket_pattern = re.compile(r'\[([^\]]+)\]')
    bracket_matches = bracket_pattern.findall(survey_content)

    def _split_titles(s: str):
        parts = re.split(r'\s*;\s*|\s*,\s*', s)
        return [p.strip() for p in parts if p and p.strip()]

    def _looks_like_citation(content: str) -> bool:
        # è®¤ä¸ºå«æœ‰è‡³å°‘ä¸€ä¸ªç©ºæ ¼æˆ–åˆ†å·çš„æ˜¯è®ºæ–‡æ ‡é¢˜å‹å¼•ç”¨ï¼›é¿å…è¯¯ä¼¤å¦‚ [overall_survey]
        return (';' in content) or (' ' in content)

    all_titles = []
    for content in bracket_matches:
        if _looks_like_citation(content):
            for t in _split_titles(content):
                # æ’é™¤æ˜æ˜¾çš„æ ‡ç­¾ï¼ˆæ— ç©ºæ ¼ä¸”ä»…å«å­—æ¯æ•°å­—ä¸‹åˆ’çº¿ã€å†’å·ã€è¿å­—ç¬¦ï¼‰
                if (' ' not in t) and re.fullmatch(r'[A-Za-z0-9_:-]+', t):
                    continue
                all_titles.append(t)

    # å»é‡å¹¶ä¿åº
    seen = set()
    unique_titles = []
    for t in all_titles:
        if t not in seen:
            seen.add(t)
            unique_titles.append(t)

    print(f"Found {len(unique_titles)} unique cited titles.")

    # è§£ææ ‡é¢˜åˆ°IDï¼ˆè‹¥èƒ½è§£æï¼‰ï¼Œå¹¶å»ºç«‹ç¼–å·
    title_to_number = {}
    title_to_id = {}
    citation_num = 0

    if unique_titles:
        resolved_ids = db.get_ids_from_titles(unique_titles)
        # resolved_ids = db.get_titles_from_citations(unique_titles)
        paper_infos = db.get_paper_info_from_ids([rid for rid in resolved_ids if rid is not None]) if any(resolved_ids) else []
        id_to_db_title = {info['id']: info['title'] for info in paper_infos if info is not None}

        for idx, raw_title in enumerate(unique_titles):
            resolved_id = resolved_ids[idx] if idx < len(resolved_ids) else None
            if resolved_id is None:
                # resolved_id = db.get_titles_from_citations([raw_title])[0]
                # if resolved_id is None:
                #     print(f"Skip unresolved title: '{raw_title}'")
                #     continue
                # resolved_ids[idx] = resolved_id
                print(f"Skip unresolved title: '{raw_title}'")
                continue
            citation_num += 1
            title_to_number[raw_title] = citation_num
            title_to_id[raw_title] = resolved_id
            db_title = id_to_db_title.get(resolved_id) if resolved_id is not None else None
            shown_title = db_title if db_title else raw_title
            print(f"Mapped '{raw_title}' -> [{citation_num}] {shown_title} (arXiv:{resolved_id})")

    print(f"Created citation mapping for {len(title_to_number)} titles.")

    # æ›¿æ¢æ­£æ–‡ä¸­çš„å¼•ç”¨ï¼šå°† [Title A; Title B] -> [1,2]
    cite_pattern = re.compile(r'\[([^\]]+)\]')

    def replace_citation_match(match):
        citation_text = match.group(1)
        if not _looks_like_citation(citation_text):
            return match.group(0)
        titles = _split_titles(citation_text)
        numbers = [str(title_to_number[t]) for t in titles if t in title_to_number]
        return f"[{','.join(numbers)}]" if numbers else ''

    cited_section_content_markdown = []
    for section_content_markdown in section_markdown_list:
        section_content_markdown = cite_pattern.sub(replace_citation_match, section_content_markdown)
        cited_section_content_markdown.append(section_content_markdown)

    # ç”Ÿæˆå¼•ç”¨åˆ—è¡¨ï¼ˆæŒ‰æ•°å­—é¡ºåºæ’åˆ—ï¼‰
    if title_to_number:
        print("Generating references section...")
        # åˆ›å»ºæŒ‰æ•°å­—ç¼–å·æ’åºçš„å¼•ç”¨åˆ—è¡¨
        sorted_titles = sorted(title_to_number.items(), key=lambda x: x[1])

        citation_str = ""
        for title, num in sorted_titles:
            arxiv_id = title_to_id.get(title)
            if arxiv_id:
                citation_str += f"[{num}] {title}. arXiv:{arxiv_id}\n\n"
            else:
                citation_str += f"[{num}] {title}\n\n"

        cited_section_content_markdown.append(f"## References\n\n{citation_str}")
        print(f"Generated references section with {len(sorted_titles)} citations.")

    markdown_code = '\n\n'.join(cited_section_content_markdown)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(markdown_path, exist_ok=True)
    with open(f"{markdown_path}/main.md", 'w', encoding='utf-8') as f:
        f.write(markdown_code)
    print(f"Markdown code generated and saved to {markdown_path}/main.md.")

    return markdown_code

def convert_survey_index_citations_to_arxiv(survey):
    """
    å°† survey ä¸­æ‰€æœ‰ section å’Œ subsection çš„æ•°å­—ç´¢å¼•å¼•ç”¨è½¬æ¢ä¸º arXiv ID å¼•ç”¨

    Args:
        survey: Survey å¯¹è±¡ï¼ŒåŒ…å« sections åˆ—è¡¨

    Returns:
        survey: è½¬æ¢åçš„ Survey å¯¹è±¡ï¼ˆåŸåœ°ä¿®æ”¹ï¼‰
    """
    import re

    print("Converting all index citations to arXiv ID citations in survey...")
    digit_cite_pattern = re.compile(r'\[(\d+(?:\s*,\s*\d+)*)\]')

    def convert_content_citations(content, paper_ids, content_type=""):
        """è½¬æ¢å•ä¸ªå†…å®¹å—ä¸­çš„å¼•ç”¨"""
        if not content:
            return content

        # å¦‚æœæ²¡æœ‰ paper_idsï¼Œç§»é™¤æ‰€æœ‰æ•°å­—å¼•ç”¨ï¼ˆå› ä¸ºè¿™äº›éƒ½æ˜¯é”™è¯¯çš„å¼•ç”¨ï¼‰
        if not paper_ids:
            print(f"    Warning: No paper_ids found for {content_type}, removing all digit citations")
            cleaned_content = digit_cite_pattern.sub('', content)
            return cleaned_content

        def replace_index_with_arxiv_ids(match):
            citation_text = match.group(1)
            indices = [int(idx.strip()) for idx in citation_text.split(',')]
            arxiv_ids = []

            for idx in indices:
                if 1 <= idx <= len(paper_ids):
                    paper_id = paper_ids[idx - 1]  # ç´¢å¼•ä»1å¼€å§‹ï¼Œä½†åˆ—è¡¨ä»0å¼€å§‹
                    if 'v' in paper_id:
                        paper_id = paper_id.split('v')[0]  # å»æ‰ç‰ˆæœ¬å·
                    arxiv_ids.append(paper_id)
                    print(f"    Converted {content_type} index {idx} -> {paper_id}")
                else:
                    print(f"    Warning: Index {idx} out of range for {content_type} (has {len(paper_ids)} papers)")

            if arxiv_ids:
                return f"[{'; '.join(arxiv_ids)}]"
            else:
                print(f"    Warning: No valid arXiv IDs found for citation {citation_text} in {content_type}")
                return match.group(0)  # ä¿ç•™åŸå¼•ç”¨

        return digit_cite_pattern.sub(replace_index_with_arxiv_ids, content)

    # éå†æ‰€æœ‰ sections
    for section_idx, section in enumerate(survey.sections):
        print(f"Processing section {section_idx}: {section.title}")

        # è½¬æ¢ section.content ä¸­çš„å¼•ç”¨
        if section.content:
            print(f"  Converting section content citations...")
            section.content = convert_content_citations(
                section.content,
                section.paper_ids,
                f"section '{section.title}'"
            )

        # è½¬æ¢æ¯ä¸ª subsection.content ä¸­çš„å¼•ç”¨
        if section.subsections:
            for subsection_idx, subsection in enumerate(section.subsections):
                print(f"  Processing subsection {subsection_idx}: {subsection.title}")
                if subsection.content and subsection.paper_ids:
                    print(f"    Converting subsection content citations...")
                    subsection.content = convert_content_citations(
                        subsection.content,
                        subsection.paper_ids,
                        f"subsection '{subsection.title}'"
                    )

    print("Completed converting all index citations to arXiv ID citations.")
    return survey


def generate_markdown_code(survey, markdown_path, api_model, db):
    """
    ç”Ÿæˆ markdown ä»£ç ï¼Œå°† arXiv ID å¼•ç”¨è½¬æ¢ä¸ºæ•°å­—å¼•ç”¨
    æ³¨æ„ï¼šè°ƒç”¨æ­¤å‡½æ•°å‰åº”å…ˆè°ƒç”¨ convert_survey_index_citations_to_arxiv() è½¬æ¢ç´¢å¼•å¼•ç”¨
    """
    from src.prompt import TO_MD_PROMPT, FOREST_TO_MERMAID_PROMPT

    def extract_markdown_code(response):
        # æ‰¾åˆ° ```markdown çš„å¼€å§‹ä½ç½®
        start_marker = '```markdown\n'
        start_idx = response.find(start_marker)
        if start_idx == -1:
            return ""

        # ä»å¼€å§‹ä½ç½®ä¹‹åå¯»æ‰¾å†…å®¹
        content_start = start_idx + len(start_marker)

        # æ‰¾åˆ°æœ€åä¸€ä¸ª ```
        end_idx = response.rfind('```')
        if end_idx <= start_idx:
            return ""

        return response[content_start:end_idx]

    def extract_mermaid_code(response):
        pattern = r'```mermaid\n(.*?)\n```'
        match = re.search(pattern, response, re.DOTALL)
        if match:
            return match.group(1)
        return ""

    section_markdown_list = []
    section_markdown_list.append(f"# {survey.title}")
    section_markdown_list.append(f"\n{survey.abstract}")  # Abstractä½œä¸ºå†…å®¹è€Œä¸æ˜¯æ ‡é¢˜

    for section_idx, section in enumerate(survey.sections):
        print(f"Generating markdown code for section {section_idx}...")
        section_title_w_fig = f"## {section.title}\n\n"
        if section.figs:
            print(f"Section {section.title} has {len(section.figs)} figures.")
            for fig in section.figs.values():
                if 'begin{forest}' in fig:
                    mermaid_code = ""
                    for attempt in range(3):
                        response = api_model.chat(FOREST_TO_MERMAID_PROMPT.replace("{{FOREST_CONTENT}}", fig))
                        mermaid_code = extract_mermaid_code(response)
                        if len(mermaid_code) > 0:
                            break
                        else:
                            print(f"Warning: Failed to convert forest tree to mermaid code, attempt {attempt + 1} of 3")
                    section_title_w_fig += mermaid_code + '\n\n'
                else:
                    section_title_w_fig += fig + '\n\n'
        if section.tables:
            print(f"Section {section.title} has {len(section.tables)} tables.")
            for table in section.tables.values():
                section_title_w_fig += table + '\n\n'
        section_content = section.to_content_str()
        section_content = section_content.replace(f"## {section.title}\n", section_title_w_fig)

        prompt = TO_MD_PROMPT.replace("{{SECTION_CONTENT}}", section_content)
        response = api_model.chat(prompt)
        section_content_markdown = extract_markdown_code(response)

        section_markdown_list.append(section_content_markdown)

    # åŒ¹é…æ‰€æœ‰ [arxiv_id] æ ¼å¼çš„å¼•ç”¨å¹¶æ›¿æ¢ä¸ºæ•°å­—å¼•ç”¨æ ¼å¼
    # åªåŒ¹é…åŒ…å«arXiv IDæ ¼å¼çš„ä¸­æ‹¬å·å†…å®¹ï¼Œé¿å…åŒ¹é…å…¶ä»–ä¸­æ‹¬å·æ–‡æœ¬
    cite_pattern = re.compile(r'\[([^\]]*\d{2,4}\.\d{2,5}(?:v\d+)?[^\]]*)\]')

    # é¦–å…ˆä»æ•´ä¸ªsurveyä¸­æå–æ‰€æœ‰å¼•ç”¨æ¥å»ºç«‹ç»Ÿä¸€çš„å¼•ç”¨æ˜ å°„
    print("Extracting all citations from survey content...")
    survey_content = '\n'.join(section_markdown_list)
    all_citations = extract_arxiv_id(survey_content)
    print(f"Found {len(all_citations)} citations: {all_citations}")

    # åˆ›å»ºå¼•ç”¨æ˜ å°„ï¼šarxiv_id -> æ•°å­—ç¼–å·
    citations_id_map = {}
    cited_title_map = {}
    citation_num = 0

    # ä»æ•°æ®åº“è·å–è®ºæ–‡ä¿¡æ¯
    cited_info = db.get_paper_info_from_ids(all_citations)

    for arxiv_id, arxiv_info in zip(all_citations, cited_info):
        try:
            if arxiv_info is not None:
                cited_title_map[arxiv_id] = arxiv_info['title']
                citation_num += 1
                citations_id_map[arxiv_id] = citation_num
                print(f"Mapped {arxiv_id} -> [{citation_num}] {arxiv_info['title']}")
            else:
                print(f"Warning: No title found for citation: {arxiv_id}")
        except Exception as e:
            print(f"Warning: Error processing citation {arxiv_id}: {e}")

    print(f"Created citation mapping for {len(citations_id_map)} papers.")

    def replace_citation_match(match):
        citation_text = match.group(1)
        # ä½¿ç”¨å¤šç§åˆ†éš”ç¬¦åˆ†å‰²å¼•ç”¨ï¼šåˆ†å·ã€é€—å·ã€ç©ºæ ¼
        individual_citations = re.split(r'[;,\s]+', citation_text)
        citation_numbers = []

        for citation in individual_citations:
            citation = citation.strip()
            citation = citation.split('v')[0]
            if citation and is_arxiv_id(citation):
                if citation in citations_id_map:
                    citation_numbers.append(str(citations_id_map[citation]))

        if citation_numbers:
            return f"[{','.join(citation_numbers)}]"
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„arXiv IDï¼Œåˆ é™¤å¼•ç”¨
            return ''

    cited_section_content_markdown = []
    for section_content_markdown in section_markdown_list:
        section_content_markdown = cite_pattern.sub(replace_citation_match, section_content_markdown)
        cited_section_content_markdown.append(section_content_markdown)

    # ç”Ÿæˆå¼•ç”¨åˆ—è¡¨ï¼ˆæŒ‰æ•°å­—é¡ºåºæ’åˆ—ï¼‰
    if citations_id_map:
        print("Generating references section...")
        # åˆ›å»ºæŒ‰æ•°å­—ç¼–å·æ’åºçš„å¼•ç”¨åˆ—è¡¨
        sorted_citations = sorted(citations_id_map.items(), key=lambda x: x[1])

        citation_str = ""
        for arxiv_id, citation_num in sorted_citations:
            if arxiv_id in cited_title_map:
                citation_str += f"[{citation_num}] {cited_title_map[arxiv_id]}. arXiv:{arxiv_id}\n\n"
            else:
                citation_str += f"[{citation_num}] arXiv:{arxiv_id}\n\n"

        cited_section_content_markdown.append(f"## References\n\n{citation_str}")
        print(f"Generated references section with {len(sorted_citations)} citations.")

    markdown_code = '\n\n'.join(cited_section_content_markdown)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(markdown_path, exist_ok=True)
    with open(f"{markdown_path}/main.md", 'w', encoding='utf-8') as f:
        f.write(markdown_code)
    print(f"Markdown code generated and saved to {markdown_path}/main.md.")

    return markdown_code


if __name__ == '__main__':
    # è¿è¡Œæµ‹è¯•
    # Example usage:
    import pickle
    import os
    from src.model import APIModel
    from src.database import database
    db = database()
    with open("./output/LLM-based_AI_Scientist_LLMs-based_agents_for_automatic_scientific_research_glm-4-plus_2025-07-04_00-06-06/survey.pkl", 'rb') as f:
        print('loading refined survey')
        survey = pickle.load(f)

    # Configure API settings via environment variables
    api_model = APIModel(
        model=os.environ.get("MODEL", "gpt-4o-mini"),
        api_key=os.environ.get("API_KEY"),
        api_url=os.environ.get("API_URL")
    )
    generate_markdown_code(survey, "markdown_draft", api_model, db)
