#%%
import os
os.chdir(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
import numpy as np
import re
import tiktoken
from tqdm import trange,tqdm
import time
import torch
import json
import threading
import random
import pickle
import sys

from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from rich.console import Console
from rich.progress import Progress, TextColumn, BarColumn, SpinnerColumn
from rich.panel import Panel
from rich.text import Text
from difflib import get_close_matches

from src.agents.utils import Survey, PaperCard, Action, calculate_outline_similarity
from src.model import APIModel
from src.database import database
from src.utils import tokenCounter, collate_text_with_imgs
from src.prompt import OUTLINE_UPDATE_PROMPT, PAPER_CARD_PROMPT, QUERY_FILTER_PROMPT, DECIDE_QUERY_PROMPT, QUERY_GENERATION_PROMPT, REFINE_OUTLINE_PROMPT, POST_PAPER_MAPPING_PROMPT
from src.json_schemas import Outline_schema, PaperCard_schema, QueryFilter_schema, DecideQuery_schema, QueryGeneration_schema, PaperOutlineMapping_schema, ResearchQueryItem
from src.cost_tracker import track_time, track_token_usage, PriceTracker


class DynamicOutlineWriter:
    def __init__(self, model, api_key, api_url, database, use_abs=True, input_graph=False, max_len=30000, debug=False, vision_model=None, vision_api_key=None, vision_api_url=None) -> None:
        # åŸºç¡€è®¾ç½®
        self.model = model
        self.api_key = api_key
        self.api_url = api_url
        self.vision_model = vision_model
        self.vision_api_key = vision_api_key
        self.vision_api_url = vision_api_url
        self.use_abs = use_abs
        self.max_len = max_len
        self.debug = debug
        self.input_graph = input_graph

        # åˆå§‹åŒ–console
        self.console = Console()

        # åˆå§‹åŒ–APIæ¨¡å‹å’Œæ•°æ®åº“
        self.api_model = APIModel(self.model, self.api_key, self.api_url)
        if self.vision_model is not None:
            self.vision_api_model = APIModel(self.vision_model, self.vision_api_key, self.vision_api_url)
        else:
            self.vision_api_model = self.api_model

        self.token_counter = tokenCounter()
        self.db = database

        # åŠ¨æ€outlineçŠ¶æ€ç»´æŠ¤
        self.current_outline = {}  # ç« èŠ‚å­—å…¸ {section_id: section_info}
        self.paper_ids_pool = []  # è®ºæ–‡idæ± 
        self.action_pool = []
        self.query_history = []
        self.paper_ids_to_content = {}  # è®ºæ–‡idåˆ°è®ºæ–‡å†…å®¹çš„æ˜ å°„
        self.paper_ids_to_cards = {}  # è®ºæ–‡idåˆ°è®ºæ–‡å¡ç‰‡çš„æ˜ å°„
        self.inspected_papers = []  # å·²æ£€æŸ¥çš„è®ºæ–‡

        self.history = []  # å†å²è®°å½•

    def get_token_usage(self):
        """è·å–APIä½¿ç”¨é‡"""
        return self.api_model.token_counter.get_total_usage()


    def _retrieve_papers(self, query, num=50):
        """è·å–è®ºæ–‡å†…å®¹"""
        paper_ids = self.db.get_ids_from_query(query.query, num=num)
        paper_infos = self.db.get_paper_info_from_ids(paper_ids)
        paper_titles = [r['title'] for r in paper_infos]
        if self.use_abs:
            paper_content = [r['abs'] for r in paper_infos]
            filtered = [(pid, title, content) for pid, title, content in zip(paper_ids, paper_titles, paper_content) if content.strip() != ""]
            if filtered:
                paper_ids, paper_titles, paper_content = map(list, zip(*filtered))
            else:
                paper_ids, paper_titles, paper_content = [], [], []
            paper_bibs = [[] for _ in range(len(paper_ids))]
            paper_imgs = [{} for _ in range(len(paper_ids))]
        else:
            papers = self.db.get_paper_from_ids(paper_ids, max_len=80000)
            paper_content = [p['text'] for p in papers]
            paper_bibs = [p['bibs'] for p in papers]
            paper_imgs = [p['imgs'] for p in papers]
            filtered = [(pid, title, content, bibs, imgs) for pid, title, content, bibs, imgs in zip(paper_ids, paper_titles, paper_content, paper_bibs, paper_imgs) if content.strip() != ""]
            if filtered:
                paper_ids, paper_titles, paper_content, paper_bibs, paper_imgs = map(list, zip(*filtered))
            else:
                paper_ids, paper_titles, paper_content, paper_bibs, paper_imgs = [], [], [], [], []
        return paper_ids, paper_titles, paper_content, paper_bibs, paper_imgs

    @track_time("[OutlineWriter] Retrieve Queries", excluded=True)
    def _retrieve_queries(self, queries, retrieve_papers_num=20):
        """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæŸ¥è¯¢æ£€ç´¢è®ºæ–‡

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            retrieve_papers_num: æ¯ä¸ªæŸ¥è¯¢æ£€ç´¢çš„è®ºæ–‡æ•°é‡

        Returns:
            results: [(query, paper_ids, paper_titles, paper_content, paper_bibs, paper_imgs), ...]
        """
        def _retrieve_single_query(query):
            paper_ids, paper_titles, paper_content, paper_bibs, paper_imgs = self._retrieve_papers(
                query,
                num=retrieve_papers_num
            )
            return query, paper_ids, paper_titles, paper_content, paper_bibs, paper_imgs

        results = []
        with ThreadPoolExecutor(max_workers=min(24, len(queries))) as executor:
            futures = [executor.submit(_retrieve_single_query, q) for q in queries]
            for future in as_completed(futures):
                results.append(future.result())

        return results

    def _update_paper_pool(self, paper_ids, paper_titles, paper_content, paper_bibs, paper_imgs):
        """æ›´æ–°è®ºæ–‡æ± """
        for paper_id, title, content, bibs, imgs in zip(paper_ids, paper_titles, paper_content, paper_bibs, paper_imgs):
            if paper_id not in self.paper_ids_to_content.keys():
                self.paper_ids_pool.append(paper_id)
                self.paper_ids_to_content[paper_id] = (title, content, bibs, imgs)

    def _get_paper_card_prompt(self, topic, paper_id, max_related_papers=5):
        """è·å–è®ºæ–‡æ‘˜è¦çš„prompt"""

        if isinstance(topic, dict):
            description = topic.get('description', "")
            topic = topic.get('topic', "")
        else:
            topic = topic.strip()
            description = ""
        paper_title = self.paper_ids_to_content[paper_id][0]
        paper_content = self.paper_ids_to_content[paper_id][1]
        paper_bibs = self.paper_ids_to_content[paper_id][2]
        paper_imgs = self.paper_ids_to_content[paper_id][3]
        paper = f"Title: {paper_title}\nContent:\n{paper_content}"

        paper_bibs_str = ""
        if len(paper_bibs) > 0:
            for bib in paper_bibs:
                paper_bibs_str += f"index: {bib['id']}\n"
                paper_bibs_str += f"citation_key: {bib['citation_key']}\n"
                paper_bibs_str += f"title: {bib['title']}\n"
                paper_bibs_str += f"authors: {bib['authors']}\n"
                paper_bibs_str += f"publication_info: {bib['publication_info']}\n"
                paper_bibs_str += "\n"
        else:
            paper_bibs_str = "Extracted failed, please extract from paper content."

        prompt = PAPER_CARD_PROMPT.format(topic=topic, paper=paper, extracted_bibliography=paper_bibs_str, max_related_papers=max_related_papers, description=description)
        if self.input_graph:
            prompt = collate_text_with_imgs(prompt, paper_imgs)
        return prompt

    def _get_update_outline_prompt(self, topic, existing_outline, current_queries, current_paper_ids, max_sections=10):
        """è·å–æ›´æ–°outlineçš„prompt
        
        Args:
            current_queries: å¯ä»¥æ˜¯å•ä¸ª ResearchQueryItem æˆ– ResearchQueryItem åˆ—è¡¨
        """

        if isinstance(topic, dict):
            description = topic.get('description', "")
            topic = topic.get('topic', "")
        else:
            topic = topic.strip()
            description = ""
        paper_cards = [self.paper_ids_to_cards.get(pid, None) for pid in current_paper_ids]
        paper_cards = [pc for pc in paper_cards if pc is not None]

        new_papers_content = ""
        for i, card in enumerate(paper_cards):
            # new_papers_content += f"Paper {i+1}:\n"
            new_papers_content += card.to_str() + "\n"
            new_papers_content += "-----\n"

        # æ”¯æŒå•ä¸ªæˆ–å¤šä¸ª queries
        if not isinstance(current_queries, list):
            current_queries = [current_queries]
        
        query_str = ""
        for i, query in enumerate(current_queries, 1):
            if len(current_queries) > 1:
                query_str += f"Query {i}:\n"
            query_str += f"Search Query: {query.query}\nQuery Target: {query.target}\n"
            if i < len(current_queries):
                query_str += "\n"

        prompt = OUTLINE_UPDATE_PROMPT.format(
            topic=topic,
            description=description,
            existing_outline=existing_outline,
            query=query_str.strip(),
            new_papers=new_papers_content.strip(),
            max_sections=max_sections
        )
        return prompt

    @track_time("[OutlineWriter] Update Outline")
    def _update_outline(self, topic, existing_outline, current_queries, current_paper_ids, max_sections=10, description=""):
        """åŸºäºæ–°å‘ç°æ›´æ–°outline
        
        Args:
            current_queries: å¯ä»¥æ˜¯å•ä¸ª ResearchQueryItem æˆ– ResearchQueryItem åˆ—è¡¨
        """
        max_retries = 5
        retry_count = 0
        
        while retry_count < max_retries:
            prompt = self._get_update_outline_prompt(topic, existing_outline, current_queries, current_paper_ids, max_sections)
            res = self.api_model.chat_structured(prompt, Outline_schema, check_cache=False)
            
            if res is not None:
                if self.debug:
                    print(f"\n\nPrompt length: {len(prompt)} chars")
                    print(f"Papers used: {len(current_paper_ids)}")
                return res
            else:
                retry_count += 1
                if self.debug:
                    print(f"Retry {retry_count}/{max_retries}: API call failed, reducing papers...")
                
                # æ¯æ¬¡å¤±è´¥å‡å°‘ 20% çš„è®ºæ–‡
                reduce_count = max(1, len(current_paper_ids) // 5)
                current_paper_ids = current_paper_ids[:-reduce_count]
                
                if len(current_paper_ids) == 0:
                    if self.debug:
                        print("No papers left after retries, outline update failed")
                    return None
        
        if self.debug:
            print(f"Failed to generate outline after {max_retries} retries")
        return None

    def _parse_outline(self, outline_dict):
        """è§£æoutline"""
        outline = outline_dict['outline']
        query = outline_dict['query']
        return outline, query

    def _generate_paper_cards(self, topic, paper_id, max_related_papers=5):
        """ç”Ÿæˆè®ºæ–‡å¡ç‰‡"""
        prompt = self._get_paper_card_prompt(topic, paper_id, max_related_papers)
        if self.input_graph:
            res = self.vision_api_model.chat_structured(prompt, PaperCard_schema)
        else:
            res = self.api_model.chat_structured(prompt, PaperCard_schema)
        return res

    @track_time("[OutlineWriter] Update Paper Cards", excluded=True)
    @track_token_usage("[OutlineWriter] Update Paper Cards")
    def _update_paper_cards(self, topic, max_related_papers=5):
        """æ›´æ–°è®ºæ–‡å¡ç‰‡"""
        # è·å–æœªå¤„ç†çš„è®ºæ–‡ID
        unprocessed_paper_ids = [paper_id for paper_id in self.paper_ids_pool if paper_id not in self.paper_ids_to_cards.keys()]

        if len(unprocessed_paper_ids) == 0:
            print("No unprocessed paper card")
            return

        # å·²å¤„ç†çš„è®ºæ–‡IDé›†åˆï¼Œç”¨äºçº¿ç¨‹åŒæ­¥
        processed_ids = set()

        def process_paper_card(paper_id):
            """å¤„ç†ä¸€æ‰¹è®ºæ–‡çš„è¾…åŠ©å‡½æ•°"""
            # ç”Ÿæˆè¿™æ‰¹è®ºæ–‡çš„å¡ç‰‡
            try:
                paper_card = self._generate_paper_cards(topic, paper_id, max_related_papers=max_related_papers)
                paper_card = PaperCard(paper_card, paper_id)
            except Exception as e:
                if self.debug:
                    print(f"Error generating paper card for {paper_id}: {e}")
                paper_card = None

            # å¦‚æœæˆåŠŸç”Ÿæˆå¡ç‰‡
            if paper_card is not None:
                print(f"Generate paper card for {paper_id} successly.")
                self.paper_ids_to_cards[paper_id] = paper_card
                processed_ids.add(paper_id)
            else:
                self.paper_ids_pool.remove(paper_id)
            return 1

        # åˆ›å»ºçº¿ç¨‹æ± 
        with ThreadPoolExecutor(max_workers=128) as executor:
            # åˆ†æ‰¹æ¬¡å¤„ç†è®ºæ–‡
            futures = []
            # å°†æ‰€æœ‰è®ºæ–‡åˆ†æ‰¹æäº¤ç»™çº¿ç¨‹æ± 
            for paper_id in unprocessed_paper_ids:
                future = executor.submit(process_paper_card, paper_id)
                futures.append(future)

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in futures:
                future.result()

        related_paper_title = []
        # start_time = time.time()
        for paper_id in unprocessed_paper_ids:
            paper_card = self.paper_ids_to_cards.get(paper_id, None)
            if paper_card is not None:
                related_paper_title.extend(paper_card.related_papers)

        title_to_ids = {}
        if len(related_paper_title) > 0:
            # print(f"Retrieving related papers: {related_paper_title}")
            related_paper_ids = self.db.get_ids_from_titles(related_paper_title, threshold=0.6)
            for title, ids in zip(related_paper_title, related_paper_ids):
                if ids is not None:
                    title_to_ids[title] = ids

        for paper_id in unprocessed_paper_ids:
            paper_card = self.paper_ids_to_cards.get(paper_id, None)
            if paper_card is None:
                continue
            success_related_papers = []
            success_related_paper_ids = []
            for title in paper_card.related_papers:
                if title in title_to_ids:
                    success_related_papers.append(title)
                    success_related_paper_ids.append(title_to_ids[title])
            paper_card.related_paper_ids = success_related_paper_ids
            paper_card.related_papers = success_related_papers
            self.paper_ids_to_cards[paper_id] = paper_card



    def _get_next_action(self, outline_batch_size):
        if len(self.action_pool) == 0:
            return None, None
        else:
            action = self.action_pool[0]
            query, paper_ids = action.pop(outline_batch_size)
            if action.paper_num() == 0:
                self.action_pool.pop(0)
            return query, paper_ids
    
    def _get_all_actions(self, max_papers_per_update=200):
        """è·å– action_pool ä¸­æ‰€æœ‰çš„ papers å’Œ queries
        
        Args:
            max_papers_per_update: å•æ¬¡æ›´æ–°æœ€å¤šä½¿ç”¨çš„è®ºæ–‡æ•°é‡ï¼Œé¿å…è¶…è¿‡ context é™åˆ¶
        
        Returns:
            queries: æ‰€æœ‰ queries çš„åˆ—è¡¨
            paper_ids: æ‰€æœ‰å»é‡åçš„ paper_ids
        """
        if len(self.action_pool) == 0:
            return None, None
        
        all_queries = []
        all_paper_ids = []
        
        # æ”¶é›†æ‰€æœ‰ action ä¸­çš„ queries å’Œ papers
        while len(self.action_pool) > 0:
            action = self.action_pool.pop(0)
            all_queries.append(action.query)
            all_paper_ids.extend(action.paper_ids)
        
        # å»é‡ paper_idsï¼ˆä¿æŒé¡ºåºï¼‰
        seen = set()
        unique_paper_ids = []
        for pid in all_paper_ids:
            if pid not in seen:
                seen.add(pid)
                unique_paper_ids.append(pid)
        # é™åˆ¶è®ºæ–‡æ•°é‡ä»¥é¿å…è¶…è¿‡ context é™åˆ¶
        if len(unique_paper_ids) > max_papers_per_update:
            if self.debug:
                print(f"Warning: Too many papers ({len(unique_paper_ids)}), truncating to {max_papers_per_update}")
            random.shuffle(unique_paper_ids)
            unique_paper_ids = unique_paper_ids[:max_papers_per_update]
        
        return all_queries, unique_paper_ids

    @track_time("[OutlineWriter] Generate Query")
    def _generate_query(self, topic, max_query_num=5):
        if isinstance(topic, dict):
            description = topic.get('description', "")
            topic = topic.get('topic', "")
        else:
            topic = topic.strip()
            description = ""
        history_outline_str = ""
        for i, outline in enumerate(self.history[:-1]):
            history_outline_str += f"Round {i}:\n{outline.to_outline_str()}\n"
            history_outline_str += "---------\n"
        current_outline_str = self.history[-1].to_outline_str()
        searched_queries = "\n\n".join([f"Search Query: {q.query}\nQuery Target: {q.target}" for q in self.query_history])
        prompt = QUERY_GENERATION_PROMPT.format(
            topic=topic,
            description=description,
            outline_history=history_outline_str,
            current_outline=current_outline_str,
            searched_queries=searched_queries,
            max_query_num=max_query_num
        )
        res = self.api_model.chat_structured(prompt, QueryGeneration_schema)
        if res is None:
            return None
        # Flatten structured research queries into a simple list for downstream usage
        flattened_queries = []
        for item in res.research_queries.refinement:
            flattened_queries.append(item)
        for item in res.research_queries.exploration:
            flattened_queries.append(item)
        return flattened_queries

    def _filter_query(self, topic, queries, current_outline, max_query_num=5):

        if isinstance(topic, dict):
            description = topic.get('description', "")
            topic = topic.get('topic', "")
        else:
            topic = topic.strip()
            description = ""
        query_history = "\n\n".join([f"Search Query: {q.query}\nQuery Target: {q.target}" for q in self.query_history])
        candidate_queries = "\n\n".join([f"Search Query: {q.query}\nQuery Target: {q.target}" for q in queries])
        prompt = QUERY_FILTER_PROMPT.format(
            topic=topic,
            description=description,
            searched_queries=query_history,
            candidate_queries=candidate_queries,
            current_outline=current_outline,
            max_query_num=max_query_num
        )
        res = self.api_model.chat_structured(prompt, QueryFilter_schema)
        if res is None:
            return None
        # Flatten structured research queries into a simple list for downstream usage
        flattened_queries = []
        for item in res.research_queries.refinement:
            flattened_queries.append(item)
        for item in res.research_queries.exploration:
            flattened_queries.append(item)
        return flattened_queries

    @track_time("[OutlineWriter] Decide Query")
    def _decide_query(self, topic, current_outline):

        if isinstance(topic, dict):
            description = topic.get('description', "")
            topic = topic.get('topic', "")
        else:
            topic = topic.strip()
            description = ""
        query_history = "\n\n".join([f"Search Query: {q.query}\nQuery Target: {q.target}" for q in self.query_history])
        prompt = DECIDE_QUERY_PROMPT.format(
            papers_read_count=len(self.inspected_papers),
            searched_queries=query_history,
            current_outline=current_outline,
            topic=topic,
            description=description
        )
        res = self.api_model.chat_structured(prompt, DecideQuery_schema)
        if res is None:
            return None, False
        return res.thinking, res.decision
    
    @track_time("[OutlineWriter] Refine outline")
    def _refine_outline(self, topic, updated_outline, max_sections=10):
        if isinstance(topic, dict):
            description = topic.get('description', "")
            topic = topic.get('topic', "")
        else:
            topic = topic.strip()
            description = ""
        retry_num = 0
        while retry_num < 10:
            prompt = REFINE_OUTLINE_PROMPT.format(
                topic=topic,
                description=description,
                current_outline=updated_outline.to_outline_str(),
                max_sections=max_sections
            )
            res = self.api_model.chat_structured(prompt, Outline_schema, check_cache=False)
            if res is not None:
                if len(res.outline)>=5:
                    return res
                else:
                    retry_num += 1
            else:
                retry_num += 1
        return None

    @track_time("[OutlineWriter] Post Paper Mapping")
    def _post_paper_mapping(self, topic, outline, mapping_batch_size = 10):
        if isinstance(topic, dict):
            description = topic.get('description', "")
            topic = topic.get('topic', "")
        else:
            topic = topic.strip()
            description = ""
        paper_ids_to_sections = {}
        available_sections = ""
        for section in outline.sections:
            if section.subsections:
                for subsection in section.subsections:
                    available_sections += f"{subsection.title}\n"
            else:
                available_sections += f"{section.title}\n"
            available_sections += "\n"
        outline_str = outline.to_outline_str()

        def process_batch(batch_ids, max_attempts=3):
            for _ in range(max_attempts):
                paper_cards_batch = [self.paper_ids_to_cards.get(pid, None) for pid in batch_ids]
                paper_cards_batch = [pc for pc in paper_cards_batch if pc is not None]

                if not paper_cards_batch:
                    return {}

                paper_cards_str = ""
                for paper_card in paper_cards_batch:
                    paper_cards_str += f"{paper_card.to_str()}\n"
                    paper_cards_str += "-----\n"

                prompt = POST_PAPER_MAPPING_PROMPT.format(
                    topic=topic,
                    description=description,
                    outline=outline_str,
                    section_names=available_sections,
                    paper_cards=paper_cards_str
                )
                res = self.api_model.chat_structured(prompt, PaperOutlineMapping_schema)
                if res is not None and len(res.paper_mappings) == len(paper_cards_batch):
                    return {paper_cards_batch[idx].paper_id: res.paper_mappings[idx].mapping_sections for idx in range(len(paper_cards_batch))}
                else:
                    continue
            return {}

        batches = [self.paper_ids_pool[i:i+mapping_batch_size] for i in range(0, len(self.paper_ids_pool), mapping_batch_size)]

        with ThreadPoolExecutor(max_workers=64) as executor:
            batch_results = []
            for result in tqdm(executor.map(process_batch, batches), total=len(batches), desc="Mapping papers to outline sections"):
                batch_results.append(result)

        for result in tqdm(batch_results, total=len(batch_results), desc="Updating paper ids to sections"):
            paper_ids_to_sections.update(result)

        section_name_to_obj = {}

        for section in outline.sections:
            if section.subsections:
                for subsection in section.subsections:
                    section_name_to_obj[subsection.title] = subsection
            else:
                section_name_to_obj[section.title] = section

        # æ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚æœ‰æ‹¼å†™æˆ–æ ¼å¼å·®å¼‚ï¼‰
        def find_section_obj(name):
            # å…ˆç²¾ç¡®æŸ¥æ‰¾
            if name in section_name_to_obj:
                return section_name_to_obj[name]
            # å†ç”¨ difflib åšæ¨¡ç³ŠåŒ¹é…
            matches = get_close_matches(name, section_name_to_obj.keys(), n=1, cutoff=0.7)
            if matches:
                return section_name_to_obj[matches[0]]
            return None

        mapped_paper_ids = []
        for paper_id, section_names in paper_ids_to_sections.items():
            for section_name in section_names:
                obj = find_section_obj(section_name)
                if obj is not None:
                    if not hasattr(obj, "paper_ids"):
                        obj.paper_ids = []
                    obj.paper_ids.append(paper_id)
                    mapped_paper_ids.append(paper_id)
        print(f"Mapped paper ids: {mapped_paper_ids}")

        return outline

    def _extract_related_papers(self, paper_ids, outline_related_paper_num=2):
        related_paper_ids = []
        for paper_id in paper_ids:
            card = self.paper_ids_to_cards.get(paper_id, None)
            if card is None:
                continue
            _related_paper_ids = card.related_paper_ids[:outline_related_paper_num]
            related_paper_ids.extend(_related_paper_ids)
        related_paper_infos = self.db.get_paper_info_from_ids(related_paper_ids)
        related_paper_titles = [r['title'] for r in related_paper_infos]
        if self.use_abs:
            related_paper_content = [r['abs'] for r in related_paper_infos]
            filtered = [(pid, title, content) for pid, title, content in zip(related_paper_ids, related_paper_titles, related_paper_content) if content.strip() != ""]
            if filtered:
                related_paper_ids, related_paper_titles, related_paper_content = map(list, zip(*filtered))
            else:
                related_paper_ids, related_paper_titles, related_paper_content = [], [], []
            related_paper_bibs = [[] for _ in range(len(related_paper_ids))]
            related_paper_imgs = [{} for _ in range(len(related_paper_ids))]
        else:
            papers = self.db.get_paper_from_ids(related_paper_ids, max_len=80000)
            related_paper_content = [p['text'] for p in papers]
            related_paper_bibs = [p['bibs'] for p in papers]
            related_paper_imgs = [p['imgs'] for p in papers]
            filtered = [(pid, title, content, bibs, imgs) for pid, title, content, bibs, imgs in zip(related_paper_ids, related_paper_titles, related_paper_content, related_paper_bibs, related_paper_imgs) if content.strip() != ""]
            if filtered:
                related_paper_ids, related_paper_titles, related_paper_content, related_paper_bibs, related_paper_imgs = map(list, zip(*filtered))
            else:
                related_paper_ids, related_paper_titles, related_paper_content, related_paper_bibs, related_paper_imgs = [], [], [], [], []

        return related_paper_ids, related_paper_titles, related_paper_content, related_paper_bibs, related_paper_imgs

    def _add_related_paper_to_action(self, outline_related_paper_num=2):
        """ä¸ºç¬¬ä¸€ä¸ª action æ·»åŠ ç›¸å…³è®ºæ–‡"""
        if len(self.action_pool) == 0 or outline_related_paper_num <= 0:
            return
        action = self.action_pool[0]
        paper_ids = action.paper_ids
        related_paper_ids, related_paper_titles, related_paper_content, related_paper_bibs, related_paper_imgs = self._extract_related_papers(paper_ids, outline_related_paper_num=outline_related_paper_num)
        self._update_paper_pool(related_paper_ids, related_paper_titles, related_paper_content, related_paper_bibs, related_paper_imgs)
        action.add_related_paper_ids(related_paper_ids)
    
    def _add_related_papers_to_all_actions(self, outline_related_paper_num=2):
        """ä¸ºæ‰€æœ‰ actions æ·»åŠ ç›¸å…³è®ºæ–‡"""
        # å¦‚æœ outline_related_paper_num ä¸º 0ï¼Œä¸æå–ç›¸å…³è®ºæ–‡ï¼Œç›´æ¥æ ‡è®°ä¸ºå·²å¤„ç†
        if outline_related_paper_num <= 0:
            for action in self.action_pool:
                if not action.added_related_paper_ids:
                    action.added_related_paper_ids = True
            return
        
        for action in self.action_pool:
            if action.added_related_paper_ids:
                continue
            paper_ids = action.paper_ids
            related_paper_ids, related_paper_titles, related_paper_content, related_paper_bibs, related_paper_imgs = self._extract_related_papers(paper_ids, outline_related_paper_num=outline_related_paper_num)
            self._update_paper_pool(related_paper_ids, related_paper_titles, related_paper_content, related_paper_bibs, related_paper_imgs)
            action.add_related_paper_ids(related_paper_ids)

    def generate_outline(self, topic, max_sections=10, initial_papers_num=20, retrieve_papers_num=20, min_papers=200, max_papers=300, outline_batch_size=10, max_query_num=5, outline_related_paper_num=2,max_related_papers=10, update_threshold=0.5):
        if isinstance(topic, dict):
            description = topic.get('description', "")
            topic_str = topic.get('topic', "")
        else:
            topic_str = topic.strip()
            description = ""
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()

        # æ˜¾ç¤ºå¼€å§‹ä¿¡æ¯
        self.console.print(Panel.fit(
            f"[bold cyan]ğŸš€ Reading papers and generating outline[/bold cyan]\n"
            f"[yellow]Topic:[/yellow] {topic_str}\n"
            f"[dim]Max sections: {max_sections} | Initial papers: {initial_papers_num} | Max papers: {max_papers}[/dim]",
            title="[bold green]AutoSurvey2.0[/bold green]",
            border_style="cyan"
        ))
        print(f"\n[Generate outline Args] max_sections: {max_sections}, initial_papers_num: {initial_papers_num}, retrieve_papers_num: {retrieve_papers_num}, min_papers: {min_papers}, max_papers: {max_papers}, outline_batch_size: {outline_batch_size}, max_query_num: {max_query_num}, outline_related_paper_num: {outline_related_paper_num}, max_related_papers: {max_related_papers}, update_threshold: {update_threshold}")
        # åŠ¨æ€æ›´æ–°è¿‡ç¨‹
        continue_query_flag = True

        with Progress(
            SpinnerColumn(),
            TextColumn("[bold green]Outline Generation"),
            BarColumn(bar_width=40),
            "[progress.percentage]{task.percentage:>3.0f}%",
            "â€¢",
            TextColumn("[blue]{task.fields[status]}", justify="left"),
            console=self.console,
            transient=True
        ) as progress:
            # 0. åˆå§‹åŒ–ä»»åŠ¡
            task = progress.add_task("Generating...", total=max_papers, status=f"ğŸ“š Preparing...")
            # 0.0 åˆå§‹åŒ–æŸ¥è¯¢å’ŒoutlineçŠ¶æ€
            current_query = ResearchQueryItem(target="NEW_SECTION_CANDIDATE", query=f"{topic_str}: {description}")
            current_outline = f"No outline exists yet. This is the initial construction phase. Based on the topic, research queries, and new papers, propose a comprehensive initial survey outline that can serve as a foundation for future iterations. The outline should include up to {max_sections} main sections and be well-structured, covering all standard components of an academic survey paper."

            query_pool = []
            self.query_history.append(current_query)

            # 0.1 è·å–åˆå§‹è®ºæ–‡å¹¶ç”Ÿæˆåˆå§‹outline
            progress.update(task, completed=0, status=f"ğŸ” Retrieving papers (Round 0) | Papers: 0/{len(self.paper_ids_pool)}")
            initial_paper_ids, paper_titles, initial_paper_content, initial_paper_bibs, initial_paper_imgs = self._retrieve_papers(current_query, initial_papers_num)

            # 0.2 æ›´æ–°çŸ¥è¯†åº“å’Œè®ºæ–‡æ± 
            progress.update(task, completed=len(initial_paper_ids), status=f"ğŸ·ï¸ Generating {len(initial_paper_ids)} paper cards (Round 0) | Papers: 0/{len(self.paper_ids_pool)} | Action: 0")
            self._update_paper_pool(initial_paper_ids, paper_titles, initial_paper_content, initial_paper_bibs, initial_paper_imgs)

            # 0.3 æ›´æ–°actionæ± 
            self.action_pool.append(Action(current_query, initial_paper_ids))

            while True:
                round_num = len(self.history)
                inspected_count = len(self.inspected_papers)

                if self.debug:
                    print("="*100)
                    print(f"Round {round_num}")
                    print(f"Current outline: {current_outline}")
                    print(f"Inspected papers: {inspected_count}/{len(self.paper_ids_pool)}")

                # 1. ä¸ºæ–°è®ºæ–‡ç”Ÿæˆè®ºæ–‡å¡ç‰‡
                unprocessed_count = len([pid for pid in self.paper_ids_pool if pid not in self.paper_ids_to_cards.keys()])
                if unprocessed_count > 0:
                    progress.update(task, completed=inspected_count, status=f"ğŸ·ï¸ Generating {unprocessed_count} paper cards (Round {round_num}) | Papers: {inspected_count}/{len(self.paper_ids_pool)} | Action: {len(self.action_pool)}")
                    if self.debug:
                        print(f"Generating {unprocessed_count} paper cards for papers")
                    self._update_paper_cards(topic, max_related_papers=max_related_papers)

                # 2. ä¸ºæ‰€æœ‰ actions æ›´æ–°ç›¸å…³è®ºæ–‡ï¼ˆç¡®ä¿æ‰€æœ‰ action éƒ½æœ‰ç›¸å…³è®ºæ–‡ï¼‰
                # å¦‚æœ outline_related_paper_num ä¸º 0ï¼Œè·³è¿‡ç›¸å…³è®ºæ–‡æå–ï¼ŒèŠ‚çœæ—¶é—´å’Œ token
                if outline_related_paper_num > 0 and len(self.action_pool) > 0:
                    # æ£€æŸ¥æ˜¯å¦æœ‰ action è¿˜æ²¡æœ‰æ·»åŠ ç›¸å…³è®ºæ–‡
                    needs_related_papers = any(not action.added_related_paper_ids for action in self.action_pool)
                    
                    if needs_related_papers:
                        progress.update(task, completed=inspected_count, status=f"ğŸ“ Extracting related papers for all actions (Round {round_num}) | Papers: {inspected_count}/{len(self.paper_ids_pool)} | Actions: {len(self.action_pool)}")
                        self._add_related_papers_to_all_actions(outline_related_paper_num=outline_related_paper_num)

                        unprocessed_count = len([pid for pid in self.paper_ids_pool if pid not in self.paper_ids_to_cards.keys()])
                        if unprocessed_count > 0:
                            progress.update(task, completed=inspected_count, status=f"ğŸ“ Updating {unprocessed_count} extracted related paper cards (Round {round_num}) | Papers: {inspected_count}/{len(self.paper_ids_pool)} | Actions: {len(self.action_pool)}")
                            self._update_paper_cards(topic, max_related_papers=max_related_papers)
                elif outline_related_paper_num == 0 and len(self.action_pool) > 0:
                    # æ ‡è®°æ‰€æœ‰ actions ä¸ºå·²å¤„ç†ï¼Œé¿å…é‡å¤æ£€æŸ¥
                    for action in self.action_pool:
                        if not action.added_related_paper_ids:
                            action.added_related_paper_ids = True


                # 3. æ›´æ–° outline
                # 3.0 è·å– action_pool ä¸­æ‰€æœ‰çš„ queries å’Œ papersï¼ˆä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰ actionsï¼‰
                current_queries, current_paper_ids = self._get_all_actions(max_papers_per_update=outline_batch_size)
                
                for retry_cnt in range(3):
                    if retry_cnt == 1:
                        print("Outline update is too aggressive, retrying...")

                    if current_queries is None or current_paper_ids is None:
                        if self.debug:
                            print("No actions in pool, skipping outline update")
                        continue

                    # 3.1 åŸºäºæ–°å‘ç°çš„è®ºæ–‡æ›´æ–°outlineç»“æ„
                    progress.update(task, completed=inspected_count, status=f"ğŸ“ Updating outline (Round {round_num}) | Papers: {inspected_count}/{len(self.paper_ids_pool)} | Queries: {len(current_queries)}")
                    self.inspected_papers.extend(current_paper_ids)
                    if self.debug:
                        print(f"\nUpdating outline with {len(current_queries)} queries and {len(current_paper_ids)} papers")
                        for i, q in enumerate(current_queries, 1):
                            print(f"  Query {i}: {q.query} (Target: {q.target})")
                    
                    current_response = self._update_outline(topic, current_outline, current_queries, current_paper_ids, max_sections=max_sections)

                    if current_response is None:
                        if self.debug:
                            print("Failed to generate outline after retries.")
                        continue

                    current_response = Survey.from_outline_schema(current_response)
                    print(f"Change Log {len(self.history)}:\n{'\n'.join(current_response.change_log)}")
                    print(f"Outline {len(self.history)}:\n{current_response.to_outline_str()}")
                    
                    # æ‰“å°æ‰€æœ‰å¤„ç†çš„ queries
                    print(f"Processed {len(current_queries)} queries in this round:")
                    for i, q in enumerate(current_queries, 1):
                        print(f"  Query {i}: {q.query} | Target: {q.target}")
                    print()  # ç©ºè¡Œåˆ†éš”

                    if round_num == 0:
                        # åˆå§‹ outline ä¸åšç›¸ä¼¼åº¦æ£€æµ‹
                        if len(current_response.sections) < (max_sections // 2):
                            print(f"{current_response}\nåˆå§‹outlineå¤ªçŸ­ï¼Œé‡è¯•")
                        else:
                            break
                    if round_num > 0:
                        similarity = calculate_outline_similarity(self.history[-1].to_outline_str(), current_response.to_outline_str())
                        print(f"Similarity: {similarity}")
                        if similarity < update_threshold:
                            print("Outline update is tooæ¿€è¿›ï¼Œæ‹’ç»æ›´æ–°")
                            current_response = self.history[-1]
                        else:
                            print("Outline update is accepted")
                            break

                if round_num > 0:
                    current_response.change_log = self.history[-1].change_log + current_response.change_log

                self.history.append(current_response)
                current_outline = current_response.to_outline_str()

                # 4. åŸºäºå½“å‰outlineå’Œå·²æ£€ç´¢è®ºæ–‡ç”Ÿæˆæ–°çš„æœç´¢æŸ¥è¯¢
                inspected_count = len(self.inspected_papers)
                if len(self.inspected_papers) < max_papers:
                    progress.update(task, completed=inspected_count, status=f"ğŸ” Generating search queries (Round {round_num}) | Papers: {inspected_count}/{len(self.paper_ids_pool)} | Action: {len(self.action_pool)}")
                    current_query = self._generate_query(topic, max_query_num=max_query_num)
                    if current_query is not None:
                        query_pool.extend(current_query)

                # 5. åŸºäºç”Ÿæˆçš„æŸ¥è¯¢æ£€ç´¢æ–°è®ºæ–‡
                # 5.0 å½“actionæ± ä¸ºç©ºæ—¶ï¼Œè¿‡æ»¤å¹¶æ‰§è¡Œæ–°æŸ¥è¯¢
                if len(self.action_pool) == 0 and len(self.inspected_papers) < max_papers:
                    progress.update(task, completed=inspected_count, status=f"ğŸ” Filtering & retrieving papers (Round {round_num}) | Papers: {inspected_count}/{len(self.paper_ids_pool)} | Action: {len(self.action_pool)}")
                    if len(query_pool) > max_query_num:
                        # generated_queries = self._filter_query(topic, query_pool, current_outline, max_query_num=max_query_num)
                        # if generated_queries is None:
                        generated_queries = random.sample(query_pool, max_query_num)
                    else:
                        generated_queries = query_pool
                    if self.debug:
                        print(f"Generated queries: {generated_queries}")

                    # 5.1 å¹¶è¡Œæ‰§è¡ŒæŸ¥è¯¢å¹¶æ›´æ–°è®ºæ–‡æ± 
                    retrieve_results = self._retrieve_queries(generated_queries, retrieve_papers_num=retrieve_papers_num)

                    # å¤„ç†æ£€ç´¢ç»“æœï¼Œæ›´æ–°å…±äº«æ•°æ®ç»“æ„
                    for query, query_paper_ids, query_paper_titles, query_paper_content, query_paper_bibs, query_paper_imgs in retrieve_results:
                        progress.update(task, completed=inspected_count, status=f"ğŸ” Retrieved papers for query (Round {round_num}) | Papers: {inspected_count}/{len(self.paper_ids_pool)} | Action: {len(self.action_pool)}")
                        self.query_history.append(query)
                        self._update_paper_pool(query_paper_ids, query_paper_titles, query_paper_content, query_paper_bibs, query_paper_imgs)
                        self.action_pool.append(Action(query, query_paper_ids))
                    
                    query_pool = []

                    # 6. å†³å®šæ˜¯å¦ç»§ç»­æ£€ç´¢æ›´å¤šè®ºæ–‡
                    if len(self.inspected_papers) >= min_papers:
                        progress.update(task, completed=inspected_count, status=f"ğŸ¤” Deciding next action (Round {round_num}) | Papers: {inspected_count}/{len(self.paper_ids_pool)} | Action: {len(self.action_pool)}")
                        continue_query_thinking, continue_query_flag = self._decide_query(topic, current_outline)
                        if self.debug:
                            print(f"Decide Query: {continue_query_thinking}")
                            print(f"Continue Query: {continue_query_flag}")

                        decision_text = "Continue" if continue_query_flag else "Stop"
                        progress.update(task, completed=inspected_count, status=f"âœ“ Decision: {decision_text} | Round {round_num} completed | Papers: {inspected_count}/{len(self.paper_ids_pool)} | Action: {len(self.action_pool)}")

                if (len(self.inspected_papers) >= max_papers and len(self.action_pool)==0) or (not continue_query_flag and len(self.action_pool) == 0):
                    break

            # å®Œæˆä¸»è¿›åº¦æ¡
            final_inspected = len(self.inspected_papers)
            progress.update(task, completed=min(final_inspected, max_papers), status=f"ğŸ”§ Refining final outline... | Papers: {final_inspected}/{len(self.paper_ids_pool)} | Action: {len(self.action_pool)}")

            # 7. ä¼˜åŒ–å’Œå®Œå–„æœ€ç»ˆoutline
            # 7.1 å¯¹outlineè¿›è¡Œæœ€ç»ˆç²¾åŒ–ï¼Œç¡®ä¿ç»“æ„åˆç†
            print("\n\nRefining final outline...")
            max_attempts = 3
            attempt = 0
            refined_outline = None

            while attempt < max_attempts:
                attempt += 1
                print(f"\nAttempt {attempt} to refine outline:")
                refined_outline = self._refine_outline(topic, self.history[-1], max_sections=max_sections)

                if refined_outline is None:
                    refined_outline = self.history[-1]
                    print(f"Attempt {attempt}: refine_outline returned None, using previous outline")
                    continue

                print(f"Change Log {len(self.history)}: {refined_outline.change_log}")
                refined_outline = Survey.from_outline_schema(refined_outline)
                similarity = calculate_outline_similarity(self.history[-1].to_outline_str(), refined_outline.to_outline_str())
                print(f"Outline {len(self.history)}: {refined_outline.to_outline_str()}")
                print(f"Similarity: {similarity}")
                if similarity < 0.5:
                    print(f"Attempt {attempt}: Outline update is too æ¿€è¿›ï¼Œæ‹’ç»æ›´æ–°")
                    refined_outline = None
                else:
                    print(f"Attempt {attempt}: Outline update is accepted")
                    refined_outline.paper_ids_to_cards = self.paper_ids_to_cards
                    refined_outline.change_log = self.history[-1].change_log + refined_outline.change_log
                    self.history.append(refined_outline)
                    break

            # å¦‚æœä¸‰æ¬¡éƒ½å¤±è´¥ï¼Œå°±ä¿ç•™æ—§çš„ outline
            if refined_outline is None:
                print("ä¸‰æ¬¡å°è¯•éƒ½æœªé€šè¿‡ï¼Œä¿ç•™åŸå§‹ outline")
                refined_outline = self.history[-1]
            
            print(f"\n\nOutline {len(self.history)}: {refined_outline.to_outline_str()}")

            # 7.2 å°†è®ºæ–‡æ˜ å°„åˆ°å¯¹åº”çš„ç« èŠ‚å’Œå­ç« èŠ‚
            progress.update(task, completed=min(final_inspected, max_papers), status=f"ğŸ”§ Mapping papers to outline... | Papers: {final_inspected}/{len(self.paper_ids_pool)} | Action: {len(self.action_pool)}")
            final_outline = self._post_paper_mapping(topic, refined_outline) if refined_outline is not None else None
            final_outline.paper_ids_to_cards = self.paper_ids_to_cards
            if final_outline is not None:
                self.history.append(final_outline)
            else:
                final_outline = self.history[-1]
            print(f"Change Log {len(self.history)}: Mapped papers to sections/subsections.")
            print(f"Outline {len(self.history)}: {final_outline.to_outline_str()}")

        # è®¡ç®—æ€»ç”¨æ—¶
        end_time = time.time()
        total_time = end_time - start_time

        # ç®€å•æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆåˆ†é’Ÿ:ç§’ï¼‰
        minutes = int(total_time // 60)
        seconds = int(total_time % 60)
        time_str = f"{minutes}:{seconds:02d}"

        # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
        self.console.print(Panel.fit(
            f"[bold green]âœ… Outline generation completed![/bold green]\n"
            f"[cyan]Processed {len(self.inspected_papers)} papers[/cyan]\n"
            f"[cyan]Generated {len(self.history)} versions of outline[/cyan]\n"
            f"[yellow]â±ï¸  Total time: {time_str}[/yellow]",
            title="[bold green]ğŸ‰ Task completed[/bold green]",
            border_style="green"
        ))

        if self.debug:
            print(f"Final outline: {final_outline.to_outline_str()}")
            print(f"Total execution time: {time_str}")

        return final_outline

    def save_state(self, filepath):
        state = {
            'model': self.model,
            'api_key': self.api_key,
            'api_url': self.api_url,
            'use_abs': self.use_abs,
            'max_len': self.max_len,
            'debug': self.debug,
            'paper_ids_pool': self.paper_ids_pool,
            'action_pool': [(action.query, action.paper_ids) for action in self.action_pool],
            'query_history': self.query_history,
            'paper_ids_to_content': self.paper_ids_to_content,
            'paper_ids_to_cards': self.paper_ids_to_cards,
            'inspected_papers': self.inspected_papers,
            'history': self.history,
        }
        with open(filepath, 'wb') as f:
            pickle.dump(state, f)

    @classmethod
    def load_state(cls, filepath, database):
        with open(filepath, 'rb') as f:
            state = pickle.load(f)
        obj = cls(
            model=state['model'],
            api_key=state['api_key'],
            api_url=state['api_url'],
            database=database,
            use_abs=state['use_abs'],
            max_len=state['max_len'],
            debug=state.get('debug', False)
        )
        obj.paper_ids_pool = state['paper_ids_pool']
        obj.action_pool = [Action(query, paper_ids) for query, paper_ids in state['action_pool']]
        obj.query_history = state['query_history']
        obj.paper_ids_to_content = state['paper_ids_to_content']
        obj.paper_ids_to_cards = state['paper_ids_to_cards']
        obj.inspected_papers = state['inspected_papers']
        obj.history = state['history']
        return obj

#%%
if __name__ == "__main__":

    db = database(converter_workers=2)
    model = "gpt-4o-mini"
    api_key = ""
    api_url = ""

    topic = "LLM-based Multi-Agent"
    outline_writer = DynamicOutlineWriter(model=model, api_key=api_key, use_abs=False, api_url=api_url, database=db, debug=True)

    #%%
    history = outline_writer.generate_outline(topic, max_sections=10, initial_papers_num=20, retrieve_papers_num=20, min_papers=800, max_papers=1200, outline_related_paper_num=3, outline_batch_size=50, max_query_num=3, update_threshold=0.5)
    # history = outline_writer.generate_outline(topic, max_sections=10, initial_papers_num=2, retrieve_papers_num=2, max_papers=10, outline_batch_size=10, max_query_num=2)

    # outline_writer.save_state("LLM_Multiagent_outline_gpt-4o-mini_full_content.pkl")

    # outline_writer = DynamicOutlineWriter.load_state("LLM_Multiagent_outline_glm4p_full_content-0626.pkl", db)
    # outline_writer.save_state("LLM_Multiagent_outline_glm4p_full_content-0629-2.pkl")
# outline_writer = DynamicOutlineWriter.load_state("LLM_Multiagent_outline_glm4p_full_content.pkl", db)


#%%
# NOTE: DO NOT RUN


