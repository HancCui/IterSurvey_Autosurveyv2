import os
import threading
import tiktoken
import time
import requests
import random
import json
import re
import base64
import io
import yaml
import subprocess
import tempfile
import shutil
import subprocess
import fitz

import mermaid as md
from tqdm import trange
from typing import List
# from langchain_community.document_loaders import PyPDFLoader  # æŒ‰éœ€å¯¼å…¥
from pathlib import Path
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
from bs4 import BeautifulSoup
from playwright.async_api import async_playwright

from .image_utils import convert_image_to_base64

class tokenCounter():
    # æ¨¡å‹ä»·æ ¼é…ç½®ï¼ˆå…ƒ/åƒtokensï¼‰[è¾“å…¥ä»·æ ¼, è¾“å‡ºä»·æ ¼, å›¾ç‰‡ä»·æ ¼]
    _model_prices_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "model_prices.json")
    with open(_model_prices_path) as fin:
        MODEL_PRICES = json.load(fin)

    def __init__(self) -> None:
        self.encoding = tiktoken.encoding_for_model("gpt-4o-mini")
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.total_cost = 0.0
        # ä¸ºè¿™ä¸ªå®ä¾‹åˆ›å»ºä¸€ä¸ªé”
        self._lock = threading.Lock()

    def num_tokens_from_string(self, string:str) -> int:
        return len(self.encoding.encode(string, disallowed_special=()))

    def num_tokens_from_list_string(self, list_of_string:List[str]) -> int:
        num = 0
        for s in list_of_string:
            num += len(self.encoding.encode(s, disallowed_special=()))
        return num

    def accumulate_usage(self, input_tokens, output_tokens, model):
        with self._lock:
            self.total_input_tokens += input_tokens
            self.total_output_tokens += output_tokens
            self.total_cost += self.compute_price(input_tokens, output_tokens, model)

    # def accumulate_usage_from_response(self, response, model):
    #     input_tokens, output_tokens = self._get_token_usage(response)
    #     self.accumulate_usage(input_tokens, output_tokens, model)

    def get_total_usage(self):
        with self._lock:
            return {"input_tokens": self.total_input_tokens, "output_tokens": self.total_output_tokens, "cost": self.total_cost}

    def compute_price(self, input_tokens, output_tokens, model):
        input_price, output_price = self.MODEL_PRICES.get(model, [0, 0])
        return (input_tokens/1000) * input_price + (output_tokens/1000) * output_price

    def text_truncation(self,text, max_len = 1000):
        encoded_id = self.encoding.encode(text, disallowed_special=())
        return self.encoding.decode(encoded_id[:min(max_len,len(encoded_id))])





def adaptive_delay(retry_count, response_time=None):
    """ä¼˜åŒ–çš„è‡ªé€‚åº”å»¶è¿Ÿç­–ç•¥"""
    base_delay = 3 if response_time is None else max(response_time * 1.5, 3)  # å‡å°‘åŸºç¡€å»¶è¿Ÿ
    retry_factor = 1.5 ** retry_count  # å‡å°æŒ‡æ•°å¢é•¿çš„å¹…åº¦
    random_factor = random.uniform(0.8, 1.2)  # å‡å°éšæœºæ³¢åŠ¨
    delay = base_delay * retry_factor * random_factor
    return min(delay, 30)  # è®¾ç½®æœ€å¤§å»¶è¿Ÿæ—¶é—´ä¸º30ç§’

def get_session_with_proxy():
    """è·å–å¸¦ä»£ç†çš„ä¼šè¯"""
    session = requests.Session()

    # è®¾ç½®æ›´ä¿å®ˆçš„é‡è¯•ç­–ç•¥
    retry_strategy = Retry(
        total=3,  # å‡å°‘é‡è¯•æ¬¡æ•°
        status_forcelist=[429, 500, 502, 503, 504],
        backoff_factor=2,
        respect_retry_after_header=True
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)

    return session

def validate_pdf(file_path):
    """éªŒè¯PDFæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆï¼Œä½¿ç”¨æ›´é«˜æ•ˆçš„æ–¹æ³•"""
    try:
        # é¦–å…ˆæ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œè¿™æ˜¯æœ€å¿«çš„æ£€æŸ¥
        file_size = os.path.getsize(file_path)
        if file_size < 10:  # æ–‡ä»¶å¤ªå°
            return False

        with open(file_path, 'rb') as f:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬çš„404æ ‡è®°æ–‡ä»¶
            header = f.read(25)  # è¯»å–è¶³å¤Ÿçš„å­—èŠ‚æ¥æ£€æŸ¥æ ‡è®°
            if header.startswith(b'%PDF not available (404)'):
                return True  # è¿™æ˜¯æˆ‘ä»¬åˆ›å»ºçš„æ ‡è®°æ–‡ä»¶ï¼Œè®¤ä¸ºæœ‰æ•ˆ

            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆæ’é™¤æ ‡è®°æ–‡ä»¶åï¼‰
            if file_size < 1024:  # å°äº1KBçš„æ–‡ä»¶è‚¯å®šä¸æ˜¯æœ‰æ•ˆçš„PDF
                return False

            # é‡ç½®æ–‡ä»¶æŒ‡é’ˆï¼Œæ£€æŸ¥çœŸå®PDFæ–‡ä»¶
            f.seek(0)
            header = f.read(8)
            if not header.startswith(b'%PDF-'):
                return False

            # å¦‚æœæ–‡ä»¶è¾ƒå°ï¼ˆå°äº10KBï¼‰ï¼Œéœ€è¦è¿›è¡Œæ›´è¯¦ç»†çš„æ£€æŸ¥
            if file_size < 10240:
                f.seek(0)
                content = f.read()
                if b'PDF.js' in content or b'Invalid PDF structure' in content:
                    return False
                content_str = content.decode('latin-1', errors='ignore')
                if 'error' in content_str.lower() or 'invalid' in content_str.lower():
                    return False
            else:
                # å¯¹äºè¾ƒå¤§çš„æ–‡ä»¶ï¼Œåªæ£€æŸ¥æ–‡ä»¶å°¾éƒ¨æ˜¯å¦æœ‰EOFæ ‡è®°
                f.seek(-1024, 2)  # ä»æ–‡ä»¶æœ«å°¾è¯»å–æœ€å1KB
                if b'%%EOF' not in f.read():
                    return False

            return True
    except Exception as e:
        return False

def validate_html(file_path):
    """éªŒè¯HTMLæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
    try:
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)
        if file_size < 10:  # æ–‡ä»¶å¤ªå°
            return False

        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

            # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬çš„404æ ‡è®°æ–‡ä»¶
            if '<!-- HTML not available (404) -->' in content:
                return True  # è¿™æ˜¯æˆ‘ä»¬åˆ›å»ºçš„æ ‡è®°æ–‡ä»¶ï¼Œè®¤ä¸ºæœ‰æ•ˆ

            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆæ’é™¤æ ‡è®°æ–‡ä»¶åï¼‰
            if file_size < 100:  # HTMLæ–‡ä»¶å¤ªå°å¯èƒ½æ˜¯é”™è¯¯é¡µé¢
                return False

            # æ£€æŸ¥æ˜¯å¦åŒ…å«åŸºæœ¬çš„HTMLç»“æ„
            content_lower = content.lower()
            if '<html' not in content_lower or '</html>' not in content_lower:
                return False

            # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯é¡µé¢
            if any(error in content_lower for error in ['404 not found', 'access denied', 'error occurred']):
                return False

            return True
    except Exception as e:
        return False

def download_paper(paper_id, cache_dir):
    """ä¸‹è½½å•ç¯‡è®ºæ–‡ï¼ˆPDFå’ŒHTMLï¼‰"""
    # æ£€æŸ¥PDFæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    pdf_path = os.path.join(cache_dir, f'{paper_id}.pdf')
    pdf_path = Path(pdf_path)
    pdf_exists = pdf_path.exists() and validate_pdf(pdf_path)

    # æ£€æŸ¥HTMLæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    html_path = os.path.join(cache_dir, f'{paper_id}.html')
    html_path = Path(html_path)
    html_exists = html_path.exists() and validate_html(html_path)

    # å¦‚æœä¸¤ä¸ªæ–‡ä»¶éƒ½å­˜åœ¨ä¸”æœ‰æ•ˆï¼Œç›´æ¥è¿”å›
    if pdf_exists and html_exists:
        return {"id": paper_id, "status": "exist"}

    # åˆ é™¤æ— æ•ˆçš„æ–‡ä»¶
    if pdf_path.exists() and not pdf_exists:
        print(f"æ–‡ä»¶ {paper_id}.pdf å­˜åœ¨ä½†æ— æ•ˆï¼Œå°è¯•é‡æ–°ä¸‹è½½")
        pdf_path.unlink()

    if html_path.exists() and not html_exists:
        print(f"æ–‡ä»¶ {paper_id}.html å­˜åœ¨ä½†æ— æ•ˆï¼Œå°è¯•é‡æ–°ä¸‹è½½")
        html_path.unlink()

    # æ„å»ºURL
    # pdf_url = f"https://arxiv.org/pdf/{paper_id}"
    # html_url = f"https://arxiv.org/html/{paper_id}"
    pdf_url = f"https://export.arxiv.org/pdf/{paper_id}"
    html_url = f"https://export.arxiv.org/html/{paper_id}"

    pdf_success = pdf_exists
    html_success = html_exists

    # è·å–å¸¦ä»£ç†çš„ä¼šè¯ï¼ˆsessionå±‚é¢å·²æœ‰retryæœºåˆ¶ï¼‰
    session = get_session_with_proxy()

    try:
        response_time = 0

        # ä¸‹è½½PDFï¼ˆå¦‚æœè¿˜æ²¡æˆåŠŸï¼‰
        if not pdf_success:
            response_start = time.time()
            # ä½¿ç”¨æµå¼ä¸‹è½½ï¼Œé¿å…æ•´ä¸ªæ–‡ä»¶é©»ç•™å†…å­˜
            with session.get(pdf_url, timeout=30, stream=True) as pdf_response:
                response_time = max(response_time, time.time() - response_start)

                if pdf_response.status_code == 404:
                    with open(pdf_path, 'wb') as f:
                        f.write(b'%PDF not available (404)')
                    pdf_success = True
                else:
                    pdf_response.raise_for_status()

                    # å…ˆæ£€æŸ¥å†…å®¹ç±»å‹ï¼Œè‹¥ä¸ºHTMLåˆ™è¿›ä¸€æ­¥å—…æ¢æ˜¯å¦éªŒè¯ç 
                    content_type = pdf_response.headers.get('Content-Type', '').lower()
                    if 'pdf' not in content_type and 'octet-stream' not in content_type:
                        # è¯»å–å°‘é‡å­—èŠ‚ä»¥åˆ¤å®šæ˜¯å¦ä¸ºéªŒè¯ç é¡µé¢
                        head_chunk = next(pdf_response.iter_content(chunk_size=1024), b'')
                        if b'recaptcha' in head_chunk.lower():
                            raise Exception("è§¦å‘äº†reCAPTCHAéªŒè¯")
                        print(f"è­¦å‘Š: {paper_id} è¿”å›çš„å†…å®¹ç±»å‹ä¸æ˜¯PDF: {content_type}")
                        # å†™å…¥å·²è¯»å–çš„å¤´éƒ¨ï¼ˆè‹¥ç¡®è®¤ä¸ºPDFåˆ™ä¼šè¡¥å…¨ï¼Œä¸æ˜¯åˆ™ä»æŒ‰å­—èŠ‚å†™å…¥ï¼‰
                        with open(pdf_path, 'wb') as f:
                            if head_chunk:
                                f.write(head_chunk)
                            for chunk in pdf_response.iter_content(chunk_size=1024 * 1024):
                                if chunk:
                                    f.write(chunk)
                    else:
                        # æ­£å¸¸PDFï¼Œæµå¼è½ç›˜
                        with open(pdf_path, 'wb') as f:
                            for chunk in pdf_response.iter_content(chunk_size=1024 * 1024):
                                if chunk:
                                    f.write(chunk)

            # éªŒè¯ä¸‹è½½çš„PDFæ–‡ä»¶
            if validate_pdf(pdf_path):
                pdf_success = True
            else:
                if pdf_path.exists():
                    pdf_path.unlink()
                raise Exception("PDFæ–‡ä»¶éªŒè¯å¤±è´¥")

        # ä¸‹è½½HTMLï¼ˆå¦‚æœè¿˜æ²¡æˆåŠŸï¼‰
        if not html_success:
            response_start = time.time()
            # ä½¿ç”¨æµå¼ä¸‹è½½ï¼Œé€å—å†™å…¥ï¼Œé¿å…æ•´é¡µé©»ç•™å†…å­˜
            with session.get(html_url, timeout=30, stream=True) as html_response:
                response_time = max(response_time, time.time() - response_start)

                if html_response.status_code == 404:
                    # å¦‚æœPDFæˆåŠŸä¸‹è½½ï¼Œä¸ºHTMLåˆ›å»ºæ ‡è®°æ–‡ä»¶
                    with open(html_path, 'w', encoding='utf-8') as f:
                        f.write('<!-- HTML not available (404) -->')
                    html_success = True
                else:
                    html_response.raise_for_status()

                    # ç›´æ¥ä»¥å­—èŠ‚æµå†™å…¥ï¼Œé¿å…åœ¨å†…å­˜ä¸­æ‹¼æ¥å¤§å­—ç¬¦ä¸²
                    with open(html_path, 'wb') as f:
                        for chunk in html_response.iter_content(chunk_size=64 * 1024):
                            if chunk:
                                f.write(chunk)

            # éªŒè¯ä¸‹è½½çš„HTMLæ–‡ä»¶
            if validate_html(html_path):
                html_success = True
            else:
                if html_path.exists():
                    html_path.unlink()
                raise Exception("HTMLæ–‡ä»¶éªŒè¯å¤±è´¥")

        # æ£€æŸ¥ä¸‹è½½ç»“æœ
        if pdf_success and html_success:
            status = "success_both"
        elif pdf_success:
            status = "success_pdf_only"
        elif html_success:
            status = "success_html_only"
        else:
            status = "fail"

        # æ·»åŠ é€‚å½“çš„å»¶è¿Ÿ
        if response_time > 0:
            wait_time = adaptive_delay(0, response_time)
            time.sleep(wait_time)

        return {"id": paper_id, "status": status}

    except Exception as e:
        print(f"è®ºæ–‡ {paper_id} ä¸‹è½½å¤±è´¥: {e}")
        
        # æ£€æŸ¥æœ€ç»ˆçŠ¶æ€ï¼Œå¦‚æœPDFæˆåŠŸä½†HTMLå¤±è´¥ï¼Œåˆ›å»ºHTMLæ ‡è®°æ–‡ä»¶
        final_pdf_success = pdf_path.exists() and validate_pdf(pdf_path)
        if final_pdf_success and not html_path.exists():
            try:
                with open(html_path, 'w', encoding='utf-8') as f:
                    f.write('<!-- HTML not available -->')
            except Exception:
                pass
        
        final_html_success = html_path.exists() and validate_html(html_path)
        
        if final_pdf_success or final_html_success:
            return {"id": paper_id, "status": "success"}
        else:
            return {"id": paper_id, "status": "fail", "reason": str(e)}

def clean_text(text: str) -> str:
    if not text:
        return ""
    # æ›¿æ¢HTMLå®ä½“
    text = text.replace('\u00a0', ' ')  # æ›¿æ¢&nbsp;
    text = text.replace('&nbsp;', ' ')
    # å»é™¤å¤šä½™ç©ºç™½
    text = re.sub(r'\s+', ' ', text.strip())
    return text

def extract_reference_info(bibitem):
    ref_info = {
        'id': '',
        'citation_key': '',
        'authors': '',
        'title': '',
        'publication_info': '',
        'doi_url': '',
        'full_text': ''
    }

    # æå–ID
    ref_info['id'] = bibitem.get('id', '')

    # å¤šç§æ–¹å¼æŸ¥æ‰¾å¼•ç”¨æ ‡ç­¾
    citation_tag = (bibitem.find('span', {'class': 'ltx_tag ltx_role_refnum ltx_tag_bibitem'}) or
                   bibitem.find('span', class_=lambda x: x and 'ltx_tag' in x and 'ltx_role_refnum' in x) or
                   bibitem.find('span', class_=re.compile(r'ltx_tag.*ltx_role_refnum')))

    if citation_tag:
        button = citation_tag.find('button')
        if button:
            button.decompose()
        ref_info['citation_key'] = clean_text(citation_tag.get_text())

    # å¤šç§æ–¹å¼æŸ¥æ‰¾bibblock
    bibblocks = (bibitem.find_all('span', {'class': 'ltx_bibblock'}) or
                bibitem.find_all('span', class_=lambda x: x and 'ltx_bibblock' in x))

    if len(bibblocks) >= 2:
        ref_info['authors'] = clean_text(bibblocks[0].get_text())
        ref_info['title'] = clean_text(bibblocks[1].get_text())

        if len(bibblocks) > 2:
            doi_link = bibblocks[2].find('a')
            if doi_link:
                ref_info['doi_url'] = doi_link.get('href', '')
            ref_info['publication_info'] = clean_text(bibblocks[2].get_text())

    # æå–å®Œæ•´æ–‡æœ¬
    full_item = bibitem
    for button in full_item.find_all('button'):
        button.decompose()
    ref_info['full_text'] = clean_text(full_item.get_text())

    return ref_info

def extract_reference(html_path):
    try:
        with open(html_path, 'r', encoding='utf-8') as f:
            content = f.read()
        soup = BeautifulSoup(content, 'html.parser')

        # å¤šç§æ–¹å¼æŸ¥æ‰¾bibliography section
        bib_section = (soup.find('section', class_='ltx_bibliography') or
                      soup.find('section', class_=lambda x: x and 'bibliography' in x) or
                      soup.find('div', class_=lambda x: x and 'bibliography' in x))
        if not bib_section:
            return []

        # å¤šç§æ–¹å¼æŸ¥æ‰¾biblist
        biblist = (bib_section.find('ul', class_='ltx_biblist') or
                  bib_section.find('ul', class_=lambda x: x and 'biblist' in x) or
                  bib_section.find('ol'))
        if not biblist:
            return []

        # å¤šç§æ–¹å¼æŸ¥æ‰¾bibitem
        bibitems = (biblist.find_all('li', class_='ltx_bibitem') or
                   biblist.find_all('li', class_=lambda x: x and 'bibitem' in x) or
                   biblist.find_all('li'))

        references = []
        for i, bibitem in enumerate(bibitems, 1):
            try:
                ref_info = extract_reference_info(bibitem)
                ref_info['index'] = i
                references.append(ref_info)
            except Exception as e:
                continue
        return references
    except Exception as e:
        return []

def collate_text_with_imgs(text, images, max_size_MB = 1):
    # å¦‚æœæ²¡æœ‰å›¾åƒæˆ–imagesä¸ºNoneï¼Œç›´æ¥è¿”å›æ–‡æœ¬
    if not images:
        return text

    content_list = []
    image_info = {} # å­˜å‚¨ base64 ç¼–ç åçš„å›¾åƒæ•°æ®å’Œç±»å‹
    image_total_num = len(images.items())
    image_fail_num = 0
    for image_name, image in images.items():
        if image is None:
            print(f"è­¦å‘Š: å›¾åƒ '{image_name}' ä¸ºNoneï¼Œè·³è¿‡å¤„ç†")
            continue

        try:
            # è½¬æ¢ä¸ºbase64
            byte_arr = convert_image_to_base64(image, max_size_MB)
            if byte_arr:
                # æ ¼å¼åŒ–ä¸º data URL
                image_url = f"data:image/jpeg;base64,{byte_arr}"
                image_info[image_name] = image_url
            else:
                print(f"è­¦å‘Š: æ— æ³•è½¬æ¢æˆ–å¤„ç†å›¾åƒ '{image_name}'")
                image_fail_num += 1
        except Exception as e:
            print(f"å¤„ç†å›¾åƒ '{image_name}' æ—¶å‡ºé”™: {e}")
            image_fail_num += 1
            continue # è·³è¿‡è¿™ä¸ªå›¾åƒï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª
        # print(f"get image base64: {byte_arr}")
    # print(f"Image process pass: {1-image_fail_num/image_total_num}")
    if not image_info:
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒï¼Œåªè¿”å›æ–‡æœ¬éƒ¨åˆ†
        return text

    # 2. æ„å»ºæ­£åˆ™è¡¨è¾¾å¼ä»¥åŒ¹é…æ‰€æœ‰å›¾åƒå ä½ç¬¦
    # å¯¹å ä½ç¬¦è¿›è¡Œè½¬ä¹‰ï¼Œä»¥é˜²åŒ…å«ç‰¹æ®Šæ­£åˆ™å­—ç¬¦
    escaped_keys = [re.escape(key) for key in image_info.keys()]
    pattern = r'(' + '|'.join(escaped_keys) + r')'

    # 3. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²æ–‡æœ¬
    # re.split ä½¿ç”¨æ•è·ç»„æ—¶ä¼šä¿ç•™åˆ†éš”ç¬¦
    parts = re.split(pattern, text)

    # 4. æ„å»º content_list
    for part in parts:
        if not part: # è·³è¿‡ç©ºå­—ç¬¦ä¸²
            continue
        if part in image_info:
            # è¿™æ˜¯ä¸€ä¸ªå›¾åƒå ä½ç¬¦
            content_list.append({
                "type": "image_url",
                "image_url": {
                    "url": image_info[part],
                    "detail": "low"
                }
            })
        else:
            # è¿™æ˜¯ä¸€ä¸ªæ–‡æœ¬ç‰‡æ®µ
            content_list.append({
                "type": "text",
                "text": part
            })

    if not content_list:
         # å¦‚æœåˆ†å‰²åä¸ºç©ºï¼Œè¿”å›åŸæ–‡æœ¬
         print("è­¦å‘Šï¼šå¤„ç†åçš„å†…å®¹åˆ—è¡¨ä¸ºç©ºã€‚")
         return text

    return content_list

def collate_text_with_bibtex(paper_info):
    if not paper_info:
        return ""

    title = (paper_info.get('title') or '').strip()
    authors = paper_info.get('authors') or []
    date = (paper_info.get('date') or '').strip()
    paper_id = (paper_info.get('id') or '').strip()
    category = (paper_info.get('cat') or '').strip()
    url = paper_info.get('url') or ''

    if not title or not authors or not paper_id:
        return ""

    if isinstance(authors, list):
        author_str = ' and '.join(authors).strip()
        first_author = authors[0] if authors else "unknown"
    else:
        author_str = str(authors).strip()
        first_author = str(authors)

    year = date[:4] if len(date) >= 4 else "unknown"

    first_author_lastname = first_author.split()[-1] if first_author.split() else "unknown"
    first_author_clean = re.sub(r'[^a-zA-Z]', '', first_author_lastname.lower())
    title_clean = re.sub(r'[^a-zA-Z0-9]', '', title.lower())[:20]
    bibkey = f"{first_author_clean}{year}{title_clean}"

    if len(bibkey) < 5:
        bibkey = re.sub(r'[^a-zA-Z0-9]', '_', paper_id)

    title_clean = title.replace('{', '').replace('}', '')
    author_clean = author_str.replace('{', '').replace('}', '')

    if 'arxiv.org' not in url and paper_id:
        url = f"https://arxiv.org/abs/{paper_id}"

    bibtex = f"""@misc{{{bibkey},
  title={{{title_clean}}},
  author={{{author_clean}}},
  year={{{year}}},
  eprint={{{paper_id}}},
  archivePrefix={{arXiv}},
  primaryClass={{{category}}},
  url={{{url}}}
}}"""

    return bibtex

def collate_bibkey(paper_info):
    if not paper_info:
        return ""

    title = (paper_info.get('title') or '').strip()
    authors = paper_info.get('authors') or []
    date = (paper_info.get('date') or '').strip()
    year = date[:4] if len(date) >= 4 else "unknown"
    if isinstance(authors, list):
        first_author = authors[0] if authors else "unknown"
    else:
        first_author = str(authors)
    first_author_lastname = first_author.split()[-1] if first_author.split() else "unknown"
    first_author_clean = re.sub(r'[^a-zA-Z]', '', first_author_lastname.lower())
    title_clean = re.sub(r'[^a-zA-Z0-9]', '', title.lower())[:20]
    bibkey = f"{first_author_clean}{year}{title_clean}"
    return bibkey



def generate_figure_latex_code(output_file, caption, label, position="h!", max_width="0.8\\textwidth", max_height="0.4\\textheight"):
    """
    ä½¿ç”¨adjustboxç”Ÿæˆæ™ºèƒ½è°ƒæ•´å¤§å°çš„LaTeXå›¾ç‰‡æ’å…¥ä»£ç 
    
    Args:
        output_file (str): å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        caption (str): å›¾ç‰‡æ ‡é¢˜
        label (str): å›¾ç‰‡æ ‡ç­¾ï¼Œç”¨äºäº¤å‰å¼•ç”¨
        position (str, optional): å›¾ç‰‡ä½ç½®å‚æ•°ï¼Œé»˜è®¤ä¸º"h!"
        max_width (str, optional): æœ€å¤§å®½åº¦ï¼Œé»˜è®¤ä¸º"0.8\\textwidth"
        max_height (str, optional): æœ€å¤§é«˜åº¦ï¼Œé»˜è®¤ä¸º"0.4\\textheight"
        
    Returns:
        str: LaTeXä»£ç å­—ç¬¦ä¸²
    """
    # å¤„ç†å›¾ç‰‡è·¯å¾„ï¼Œç¡®ä¿ä½¿ç”¨æ­£æ–œæ ï¼ˆLaTeXæ ‡å‡†ï¼‰
    latex_path = output_file.replace('\\', '/')
    
    # ç”Ÿæˆä½¿ç”¨adjustboxçš„LaTeXä»£ç 
    latex_code = f"""\\begin{{figure}}[{position}]
\\centering
\\adjustbox{{max width={max_width}, max height={max_height}, center}}{{
    \\includegraphics{{{latex_path}}}
}}
\\caption{{{caption}}}
\\label{{{label}}}
\\end{{figure}}"""

    return latex_code

async def render_mermaid_with_playwright(mermaid_code: str, output_file:str = "", theme_file: str = "themes/default_theme.json"):
    """
    ä½¿ç”¨ Playwright å’Œæ— å¤´æµè§ˆå™¨å°† Mermaid ä»£ç æ¸²æŸ“æˆPNGå›¾ç‰‡ã€‚

    Args:
        mermaid_code (str): Mermaid diagram code
        output_file (str): Path to save the rendered image. If empty, won't save to file.
        theme_file (str): Path to theme configuration JSON file. Defaults to "themes/default_theme.json".

    Returns:
        tuple: (png_data, error_message) - The rendered image data as bytes and error message if any.
                Returns (None, error_message) if rendering failed
    """
    # ç”¨äºæ”¶é›†é”™è¯¯ä¿¡æ¯
    console_messages = []
    js_errors = []

    # åŠ è½½ä¸»é¢˜é…ç½®
    try:
        with open(theme_file, 'r', encoding='utf-8') as f:
            theme_config = json.load(f)
    except FileNotFoundError:
        # ä½¿ç”¨é»˜è®¤ä¸»é¢˜é…ç½®
        theme_config = {
            "theme": "base",
            "themeVariables": {
                "primaryColor": "#4186f3",
                "primaryBorderColor": "#2a5dab",
                "primaryTextColor": "#ffffff",
                "tertiaryColor": "#fabd05",
                "tertiaryBorderColor": "#e09100",
                "tertiaryTextColor": "#000000",
                "secondaryColor": "#34a853",
                "secondaryBorderColor": "#0f7d2b",
                "secondaryTextColor": "#ffffff",
                "noteBkgColor": "#ea4335",
                "noteTextColor": "#ffffff",
                "lineColor": "#888888",
                "edgeLabelBackground": "#ffffff",
                "fontFamily": "Helvetica, Arial, sans-serif",
                "fontSize": "16px",
                "nodeRadius": "8px",
                "background": "#ffffff"
            }
        }
    except json.JSONDecodeError:
        theme_config = {
            "theme": "base",
            "themeVariables": {}
        }

    # æ„é€ ä¸€ä¸ªç®€å•çš„ HTML é¡µé¢æ¥æ‰¿è½½ Mermaid å›¾è¡¨
    html_content = f"""
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Mermaid Render</title>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.2.4/mermaid.min.js"></script>
    </head>
    <body>
        <div class="mermaid">
            {mermaid_code}
        </div>
        <div id="parse-result" style="display: none;"></div>
        <div id="render-status" style="display: none;"></div>
        <div id="script-loaded" style="display: none;">false</div>
        <script>
            let parseResult = {{"success": false, "error": ""}};
            let renderStatus = {{"success": false, "error": ""}};
            let scriptLoaded = false;

            // ç­‰å¾…DOMåŠ è½½å®Œæˆ
            window.addEventListener('DOMContentLoaded', function() {{
                console.log('DOM loaded');
                initializeMermaid();
            }});

            function initializeMermaid() {{
                // æ£€æŸ¥Mermaidæ˜¯å¦åŠ è½½æˆåŠŸ
                if (typeof mermaid !== 'undefined') {{
                    scriptLoaded = true;
                    document.getElementById('script-loaded').textContent = 'true';
                    console.log('Mermaid script loaded successfully');

                    try {{
                        // é¦–å…ˆä½¿ç”¨ mermaid.parse éªŒè¯è¯­æ³•
                        const mermaidCode = `{mermaid_code}`;
                        console.log('Parsing mermaid code:', mermaidCode.substring(0, 100) + '...');

                        const parseOutput = mermaid.parse(mermaidCode);
                        parseResult.success = true;
                        console.log('Mermaid parse successful');

                        // å¦‚æœè§£ææˆåŠŸï¼Œåˆå§‹åŒ–å¹¶æ¸²æŸ“
                        mermaid.initialize({{
                            startOnLoad: false,
                            theme: "{theme_config['theme']}",
                            themeVariables: {json.dumps(theme_config['themeVariables'])},
                            logLevel: 'debug'
                        }});

                        console.log('Mermaid initialized, starting render...');

                        // ä½¿ç”¨æ›´å¯é çš„æ¸²æŸ“æ–¹æ³•
                        setTimeout(() => {{
                            try {{
                                mermaid.run().then(() => {{
                                    renderStatus.success = true;
                                    console.log('Mermaid render successful');
                                    updateResults();
                                }}).catch((error) => {{
                                    const errorMsg = error ? (error.message || error.toString() || 'Unknown render error') : 'Empty error object';
                                    renderStatus.error = errorMsg;
                                    console.error('Mermaid render error:', error);
                                    updateResults();
                                }});
                            }} catch (syncError) {{
                                const errorMsg = syncError ? (syncError.message || syncError.toString() || 'Unknown sync error') : 'Empty sync error';
                                renderStatus.error = 'Synchronous error: ' + errorMsg;
                                console.error('Synchronous mermaid error:', syncError);
                                updateResults();
                            }}
                        }}, 1000);

                    }} catch (error) {{
                        const errorMsg = error ? (error.message || error.toString() || 'Unknown parse error') : 'Empty parse error';
                        parseResult.error = errorMsg;
                        renderStatus.error = "Parse failed, rendering skipped: " + errorMsg;
                        console.error('Mermaid parse error:', error);
                        updateResults();
                    }}
                }} else {{
                    console.error('Mermaid script failed to load');
                    parseResult.error = "Mermaid script not loaded";
                    renderStatus.error = "Mermaid script not loaded";
                    document.getElementById('script-loaded').textContent = 'false';
                    updateResults();
                }}
            }}

            function updateResults() {{
                // å°†ç»“æœå†™å…¥éšè—å…ƒç´ ä¾›Pythonè¯»å–
                document.getElementById('parse-result').textContent = JSON.stringify(parseResult);
                document.getElementById('render-status').textContent = JSON.stringify(renderStatus);
                console.log('Results updated:', {{parseResult, renderStatus}});
            }}

            // å¦‚æœDOMContentLoadedå·²ç»è§¦å‘ï¼Œç›´æ¥åˆå§‹åŒ–
            if (document.readyState === 'loading') {{
                // è¿˜åœ¨åŠ è½½ä¸­ï¼Œç­‰å¾…DOMContentLoaded
            }} else {{
                // DOMå·²ç»åŠ è½½å®Œæˆ
                initializeMermaid();
            }}
        </script>
    </body>
    </html>
    """

    async with async_playwright() as p:
        browser = await p.chromium.launch()
        page = await browser.new_page()

        # ç›‘å¬æ§åˆ¶å°æ¶ˆæ¯
        def handle_console_message(msg):
            if msg.type in ['error', 'warning']:
                console_messages.append(f"{msg.type.upper()}: {msg.text}")

        # ç›‘å¬ JavaScript é”™è¯¯
        def handle_page_error(error):
            error_msg = f"JavaScripté”™è¯¯: {error}"
            js_errors.append(error_msg)

        page.on("console", handle_console_message)
        page.on("pageerror", handle_page_error)

        try:
            # ç›´æ¥è®¾ç½®é¡µé¢å†…å®¹
            await page.set_content(html_content)

            # ç­‰å¾…é¡µé¢æ¸²æŸ“å®Œæˆï¼Œå¢åŠ è¶…æ—¶æ—¶é—´
            await page.wait_for_selector(".mermaid", timeout=15000)

            # ç­‰å¾…è¶³å¤Ÿæ—¶é—´è®©Mermaidå®Œæˆæ¸²æŸ“
            await page.wait_for_timeout(5000)

            # è¯»å–è§£æç»“æœ
            parse_result_element = await page.query_selector("#parse-result")
            render_status_element = await page.query_selector("#render-status")
            script_loaded_element = await page.query_selector("#script-loaded")

            parse_result = {}
            render_status = {}
            script_loaded = False

            if script_loaded_element:
                script_loaded_text = await script_loaded_element.text_content()
                script_loaded = script_loaded_text == 'true'

            if parse_result_element:
                parse_result_text = await parse_result_element.text_content()
                try:
                    parse_result = json.loads(parse_result_text) if parse_result_text else {}
                except json.JSONDecodeError:
                    parse_result = {"success": False, "error": "æ— æ³•è§£æparseç»“æœ"}

            if render_status_element:
                render_status_text = await render_status_element.text_content()
                try:
                    render_status = json.loads(render_status_text) if render_status_text else {}
                except json.JSONDecodeError:
                    render_status = {"success": False, "error": "æ— æ³•è§£ærenderç»“æœ"}

            # æ£€æŸ¥é¡µé¢ä¸­æ˜¯å¦æœ‰SVGå…ƒç´ 
            svg_element = await page.query_selector(".mermaid svg")

            # æ£€æŸ¥è„šæœ¬æ˜¯å¦åŠ è½½æˆåŠŸ
            if not script_loaded:
                error_message = "Mermaidè„šæœ¬åŠ è½½å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜"
                if console_messages or js_errors:
                    error_message += f"; æ§åˆ¶å°ä¿¡æ¯: {'; '.join(console_messages + js_errors)}"
                await browser.close()
                return None, error_message

            # æ£€æŸ¥Mermaidè¯­æ³•è§£æç»“æœ
            if not parse_result.get("success", False):
                error_message = f"Mermaidè¯­æ³•é”™è¯¯: {parse_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                if console_messages or js_errors:
                    # è¿‡æ»¤æ‰ç½‘ç»œè­¦å‘Šï¼Œåªä¿ç•™çœŸæ­£çš„é”™è¯¯
                    real_errors = [msg for msg in (console_messages + js_errors)
                                 if not ('parser-blocking' in msg and 'network request' in msg)]
                    if real_errors:
                        error_message += f"; æ§åˆ¶å°é”™è¯¯: {'; '.join(real_errors)}"
                await browser.close()
                return None, error_message

            # æ£€æŸ¥æ¸²æŸ“ç»“æœ
            if not render_status.get("success", False):
                error_message = f"Mermaidæ¸²æŸ“å¤±è´¥: {render_status.get('error', 'æœªçŸ¥é”™è¯¯')}"
                if console_messages or js_errors:
                    # è¿‡æ»¤æ‰ç½‘ç»œè­¦å‘Šï¼Œåªä¿ç•™çœŸæ­£çš„é”™è¯¯
                    real_errors = [msg for msg in (console_messages + js_errors)
                                 if not ('parser-blocking' in msg and 'network request' in msg)]
                    if real_errors:
                        error_message += f"; æ§åˆ¶å°é”™è¯¯: {'; '.join(real_errors)}"
                await browser.close()
                return None, error_message

            # å®šä½åˆ°æ¸²æŸ“å‡ºçš„ Mermaid å›¾è¡¨å…ƒç´ 
            diagram_element = await page.query_selector(".mermaid svg")

            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯å…ƒç´ ï¼ˆMermaid é”™è¯¯æ—¶é€šå¸¸ä¼šæ˜¾ç¤ºé”™è¯¯æ–‡æœ¬ï¼‰
            error_element = await page.query_selector(".mermaid .error, .mermaid pre")

            error_message = ""

            # æ”¶é›†æ‰€æœ‰é”™è¯¯ä¿¡æ¯
            if console_messages or js_errors:
                all_errors = console_messages + js_errors
                error_message = "; ".join(all_errors)

            if error_element:
                error_text = await error_element.text_content()
                if error_text:
                    error_message = f"Mermaidé¡µé¢é”™è¯¯: {error_text}"
                    if console_messages or js_errors:
                        error_message += f"; æ§åˆ¶å°é”™è¯¯: {'; '.join(console_messages + js_errors)}"

            if diagram_element and not error_element:
                # æ£€æŸ¥ SVG æ˜¯å¦å®é™…åŒ…å«å†…å®¹
                svg_content = await diagram_element.inner_html()
                if not svg_content.strip() or len(svg_content) < 50:  # SVG å†…å®¹å¤ªå°‘å¯èƒ½è¡¨ç¤ºæ¸²æŸ“å¤±è´¥
                    error_message = "SVGå†…å®¹å¼‚å¸¸ï¼Œå¯èƒ½æ˜¯æ¸²æŸ“å¤±è´¥"
                    await browser.close()
                    return None, error_message
                else:
                    # æˆªå–SVGå…ƒç´ ä¸ºPNG
                    png_data = await diagram_element.screenshot(type='png')

                    # å¦‚æœæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä¿å­˜ä¸ºPNGæ–‡ä»¶
                    if output_file:
                        try:
                            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                            os.makedirs(os.path.dirname(output_file), exist_ok=True)

                            # ç¡®ä¿è¾“å‡ºæ–‡ä»¶æ‰©å±•åä¸º.png
                            if not output_file.endswith('.png'):
                                output_file = output_file.rsplit('.', 1)[0] + '.png'

                            with open(output_file, 'wb') as f:
                                f.write(png_data)
                        except Exception as save_error:
                            await browser.close()
                            return None, f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(save_error)}"

                    await browser.close()
                    return png_data, error_message

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ SVG å…ƒç´ 
            if not diagram_element:
                error_message = "æœªèƒ½æ‰¾åˆ°æ¸²æŸ“çš„ Mermaid SVG å…ƒç´ "
                if console_messages or js_errors:
                    error_message += f"; æ§åˆ¶å°é”™è¯¯: {'; '.join(console_messages + js_errors)}"

            await browser.close()
            return None, error_message

        except Exception as e:
            await browser.close()
            error_message = f"æ¸²æŸ“è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}"
            if console_messages or js_errors:
                error_message += f"; æ§åˆ¶å°é”™è¯¯: {'; '.join(console_messages + js_errors)}"
            return None, error_message





def dict_to_mermaid_config(config_dict):
    # å°†å­—å…¸åŒ…è£…åœ¨ config é”®ä¸‹
    wrapped_config = {'config': config_dict}
    yaml_content = yaml.dump(wrapped_config, default_flow_style=False, allow_unicode=True)
    return f"---\n{yaml_content}---\n"


def is_valid_mermaid_image(response_content):
    if not response_content or isinstance(response_content, str):
        return False
    
    if isinstance(response_content, bytes) and len(response_content) > 0:
        return (response_content.startswith(b'\x89PNG') or 
                response_content.startswith(b'\xff\xd8\xff') or 
                b'<svg' in response_content[:100].lower())
    
    return False

def render_mermaid_with_python(mermaid_code: str, output_file: str = "", theme_file: str = "themes/default_theme.json"):
    # åŠ è½½ä¸»é¢˜é…ç½®
    try:
        with open(theme_file, 'r', encoding='utf-8') as f:
            theme_config = json.load(f)
    except FileNotFoundError:
        # ä½¿ç”¨é»˜è®¤ä¸»é¢˜é…ç½®
        theme_config = {
            "theme": "base",
            "themeVariables": {
                "primaryColor": "#4186f3",
                "primaryBorderColor": "#2a5dab",
                "primaryTextColor": "#ffffff",
                "tertiaryColor": "#fabd05",
                "tertiaryBorderColor": "#e09100",
                "tertiaryTextColor": "#000000",
                "secondaryColor": "#34a853",
                "secondaryBorderColor": "#0f7d2b",
                "secondaryTextColor": "#ffffff",
                "noteBkgColor": "#ea4335",
                "noteTextColor": "#ffffff",
                "lineColor": "#888888",
                "fontFamily": "Helvetica, Arial, sans-serif",
                "fontSize": "16px",
                "nodeRadius": "8px",
                "background": "#ffffff"
            }
        }
    except json.JSONDecodeError:
        theme_config = {
            "theme": "base",
            "themeVariables": {}
        }
    try:
        yaml_config = dict_to_mermaid_config(theme_config)
        mermaid_code_with_theme = yaml_config + mermaid_code
        render = md.Mermaid(mermaid_code_with_theme)
        if is_valid_mermaid_image(render.img_response.content):
            return render.to_png(output_file), True
        else:
            return None, False
    except Exception as e:
        print(f"Error in render_mermaid_with_python: {e}")
        return None, False




def extract_table_compilation_issues(log_content: str) -> dict:
    """
    Extract table-related issues from LaTeX compilation log, formatted for LLM use
    
    Args:
        log_content (str): LaTeX compilation log content
        
    Returns:
        dict: Categorized issue information
    """
    issues = {
        'overfull_hbox': [],    # Table too wide
        'underfull_hbox': [],   # Uneven content distribution
        'syntax_errors': [],    # Syntax errors
        'missing_packages': [], # Missing packages
        'other_warnings': []    # Other warnings
    }
    
    lines = log_content.split('\n')
    
    for i, line in enumerate(lines):
        line = line.strip()
        
        # Handle Overfull hbox (table too wide)
        if "Overfull \\hbox" in line:
            # Extract excess pixels
            pixels_match = re.search(r'(\d+\.?\d*pt) too wide', line)
            pixels = pixels_match.group(1) if pixels_match else "unknown"
            
            # Get line information
            line_info = ""
            if i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                if "in paragraph at lines" in next_line:
                    line_info = next_line
            
            issues['overfull_hbox'].append({
                'message': f"Table exceeds page width by {pixels}",
                'line_info': line_info,
                'severity': 'high'
            })
        
        # Handle Underfull hbox
        elif "Underfull \\hbox" in line:
            issues['underfull_hbox'].append({
                'message': line,
                'severity': 'medium'
            })
        
        # Handle syntax errors
        elif any(keyword in line for keyword in ['! ', 'Error', 'Missing $', 'Misplaced']):
            issues['syntax_errors'].append({
                'message': line,
                'severity': 'high'
            })
        
        # Handle missing packages
        elif "File" in line and "not found" in line:
            issues['missing_packages'].append({
                'message': line,
                'severity': 'high'
            })
        
        # Other LaTeX warnings
        elif "LaTeX Warning" in line:
            issues['other_warnings'].append({
                'message': line,
                'severity': 'low'
            })
    
    return issues


def format_issues_for_llm(issues: dict) -> str:
    """
    Format compilation issues for LLM understanding
    
    Args:
        issues (dict): Issues dictionary
        
    Returns:
        str: Formatted problem description
    """
    formatted_text = []
    
    # Sort by severity
    if issues['overfull_hbox']:
        formatted_text.append("ğŸš¨ **Table Width Issues**:")
        for issue in issues['overfull_hbox']:
            formatted_text.append(f"  - {issue['message']}")
            if issue['line_info']:
                formatted_text.append(f"    Location: {issue['line_info']}")
    
    if issues['syntax_errors']:
        formatted_text.append("\nâŒ **Syntax Errors**:")
        for issue in issues['syntax_errors']:
            formatted_text.append(f"  - {issue['message']}")
    
    if issues['missing_packages']:
        formatted_text.append("\nğŸ“¦ **Missing Packages**:")
        for issue in issues['missing_packages']:
            formatted_text.append(f"  - {issue['message']}")
    
    if issues['underfull_hbox']:
        formatted_text.append("\nâš ï¸ **Content Distribution Warnings**:")
        for issue in issues['underfull_hbox']:
            formatted_text.append(f"  - {issue['message']}")
    
    if issues['other_warnings']:
        formatted_text.append("\nğŸ’¡ **Other Warnings**:")
        for issue in issues['other_warnings']:
            formatted_text.append(f"  - {issue['message']}")
    
    return '\n'.join(formatted_text) if formatted_text else "No significant issues"


def check_latex_table_acceptable(table_code: str) -> tuple[bool, str]:
    """
    Check LaTeX table and provide detailed, formatted feedback for LLM
    
    Args:
        table_code (str): LaTeX table code
        
    Returns:
        tuple: (whether there are issues, formatted problem description)
    """
    # Use temporary directory
    with tempfile.TemporaryDirectory() as temp_dir:
        try:
            # Read project template
            template_dir = "./latex_draft"
            
            # Read document head
            with open(os.path.join(template_dir, "document_head.txt"), "r", encoding="utf-8") as f:
                document_head = f.read()
            
            # Read document tail
            with open(os.path.join(template_dir, "document_tail.txt"), "r", encoding="utf-8") as f:
                document_tail = f.read()
            
            # Replace placeholders to avoid compilation errors
            document_head = document_head.replace("SURVEY_TITLE", "Test Survey")
            document_head = document_head.replace("SURVEY_ABSTRACT", "This is a test abstract.")
            
            # Create complete LaTeX document
            latex_code = document_head + "\n\n" + table_code + "\n\n" + document_tail
            
            # Copy style file to temporary directory
            style_file = os.path.join(template_dir, "nips_2024.sty")
            if os.path.exists(style_file):
                shutil.copy(style_file, temp_dir)
            
            # Write LaTeX code to temporary directory
            tex_file = os.path.join(temp_dir, "test_table.tex")
            with open(tex_file, "w", encoding="utf-8") as f:
                f.write(latex_code)
            
            # Compile in temporary directory
            result = subprocess.run(["pdflatex", "-interaction=nonstopmode", "test_table.tex"], 
                                  cwd=temp_dir, 
                                  stdout=subprocess.PIPE, 
                                  stderr=subprocess.PIPE,
                                  timeout=30,
                                  text=True)
            
            # Check log file
            log_file = os.path.join(temp_dir, "test_table.log")
            if os.path.exists(log_file):
                with open(log_file, "r", encoding="utf-8") as log:
                    content = log.read()
                
                # Extract and format issues
                issues = extract_table_compilation_issues(content)
                
                # Check for serious issues
                has_serious_issues = (
                    result.returncode != 0 or 
                    issues['overfull_hbox'] or 
                    issues['syntax_errors'] or 
                    issues['missing_packages']
                )
                
                if has_serious_issues:
                    return False, issues
                else:
                    return True, "Compilation successful, no serious issues"
            else:
                return False, "Compilation failed, no log file generated"
                
        except subprocess.TimeoutExpired:
            return False, "Compilation timeout (30 seconds)"
        except Exception as e:
            return False, f"Compilation error: {str(e)}"


def check_mermaid_code_acceptable(mermaid_code: str) -> tuple[bool, str]:
    """
    Check if Mermaid code can be rendered successfully
    
    Args:
        mermaid_code (str): Mermaid diagram code to check
        
    Returns:
        tuple: (success, error_message)
            - success: True if code can be rendered, False otherwise
            - error_message: Error description if rendering fails, empty string if successful
    """
    try:
        png_data, success = render_mermaid_with_python(mermaid_code)
        
        if success and png_data:
            return True, ""
        else:
            return False, "Mermaid code rendering failed"
            
    except Exception as e:
        return False, f"Mermaid code validation failed: {str(e)}"


def check_mermaid_diagram_readability(mermaid_code: str) -> dict:
    """
    Check Mermaid diagram readability by rendering, compiling in LaTeX, and generating screenshot
    """
    with tempfile.TemporaryDirectory() as temp_dir:
        # Generate PNG file
        png_output = os.path.join(temp_dir, "mermaid_diagram.png")
        png_data, render_success = render_mermaid_with_python(mermaid_code, png_output)
        
        if not render_success:
            return {'success': False, 'message': "Mermaid PNG generation failed"}
        
        # Generate LaTeX figure code
        figure_code = generate_figure_latex_code(
            output_file="mermaid_diagram.png",
            caption="This image is a mermaid diagram, you should read the figure and judge whether it is readable for the reader.",
            label="fig:mermaid_diagram"
        )
        
        # Compile LaTeX with the figure
        template_dir = "./latex_draft"
        
        # Read template files
        with open(os.path.join(template_dir, "document_head.txt"), "r") as f:
            doc_head = f.read().replace("SURVEY_TITLE", "Test").replace("SURVEY_ABSTRACT", "Test")
        with open(os.path.join(template_dir, "document_tail.txt"), "r") as f:
            doc_tail = f.read()
        
        # Create complete LaTeX document
        latex_code = doc_head + "\n\n" + figure_code + "\n\n" + doc_tail
        
        # Copy style file
        shutil.copy(os.path.join(template_dir, "nips_2024.sty"), temp_dir)
        
        # Write and compile LaTeX
        with open(os.path.join(temp_dir, "test.tex"), "w") as f:
            f.write(latex_code)
        
        result = subprocess.run(["pdflatex", "-interaction=nonstopmode", "test.tex"], 
                              cwd=temp_dir, capture_output=True, timeout=30)
        
        if result.returncode != 0:
            return {'success': False, 'message': "LaTeX compilation failed"}
        
        try:
            doc = fitz.open(os.path.join(temp_dir, "test.pdf"))
            page = doc[0]  # Get first page
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x scale for better quality
            img_data = pix.tobytes("png")
            
            # Convert to PIL Image for base64 encoding
            from PIL import Image
            img = Image.open(io.BytesIO(img_data))
            screenshot_base64 = convert_image_to_base64(img, max_size_MB=5)
            
            doc.close()
            
            if screenshot_base64:
                return {
                    'success': True,
                    'screenshot_base64': screenshot_base64,
                    'message': "Mermaid diagram compiled successfully"
                }
        except Exception as e:
            print(f"Error in check_mermaid_diagram_readability: {e}")
            pass
        
        return {'success': False, 'message': "Screenshot generation failed"}
        
